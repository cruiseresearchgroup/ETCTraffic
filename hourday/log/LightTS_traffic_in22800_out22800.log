nohup: ignoring input
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=151, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems03_all_common_flow.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='LightTS', model_id='pems03_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=22800, root_path='../../data/pems/', seasonal_patterns='Monthly', seq_len=22800, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_96_96_LightTS_custom_ftM_sl22800_ll48_pl22800_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1558788
val 206400
test 435597
Traceback (most recent call last):
  File "run.py", line 147, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/dddtimesnet/exp/exp_long_term_forecasting.py", line 201, in train
    loss.backward()
  File "/jobfs/115974024.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/jobfs/115974024.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 2.19 GiB (GPU 0; 31.73 GiB total capacity; 26.44 GiB already allocated; 1.86 GiB free; 28.68 GiB reserved in total by PyTorch)
