nohup: ignoring input
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=151, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems03_all_common_flow.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='traffic_168_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=5100, root_path='../../data/pems/', seasonal_patterns='Monthly', seq_len=5100, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_traffic_168_96_Autoformer_custom_ftM_sl5100_ll48_pl5100_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1594188
val 224100
test 453297
Traceback (most recent call last):
  File "run.py", line 147, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/dddtimesnet/exp/exp_long_term_forecasting.py", line 201, in train
    loss.backward()
  File "/jobfs/116050595.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/jobfs/116050595.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.26 GiB (GPU 0; 31.73 GiB total capacity; 27.54 GiB already allocated; 1.03 GiB free; 29.50 GiB reserved in total by PyTorch)
