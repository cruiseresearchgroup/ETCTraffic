Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5383
val 703
test 1497
	iters: 100, epoch: 1 | loss: 0.4938209
	speed: 0.0264s/iter; left time: 883.9400s
Epoch: 1 cost time: 4.228101491928101
Epoch: 1, Steps: 168 | Train Loss: 0.5479623 Vali Loss: 0.3559936 Test Loss: 0.5123439
Validation loss decreased (inf --> 0.355994).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.4596878
	speed: 0.0880s/iter; left time: 2934.3196s
Epoch: 2 cost time: 4.122769832611084
Epoch: 2, Steps: 168 | Train Loss: 0.5191136 Vali Loss: 0.3537782 Test Loss: 0.5093209
Validation loss decreased (0.355994 --> 0.353778).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.4816093
	speed: 0.0879s/iter; left time: 2913.5911s
Epoch: 3 cost time: 4.048736095428467
Epoch: 3, Steps: 168 | Train Loss: 0.5167890 Vali Loss: 0.3526087 Test Loss: 0.5071617
Validation loss decreased (0.353778 --> 0.352609).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.5938712
	speed: 0.0921s/iter; left time: 3039.0803s
Epoch: 4 cost time: 4.171695232391357
Epoch: 4, Steps: 168 | Train Loss: 0.5162285 Vali Loss: 0.3546163 Test Loss: 0.5054071
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 5 | loss: 0.4580329
	speed: 0.0883s/iter; left time: 2899.7344s
Epoch: 5 cost time: 4.009158372879028
Epoch: 5, Steps: 168 | Train Loss: 0.5159975 Vali Loss: 0.3535392 Test Loss: 0.5090862
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 6 | loss: 0.5416057
	speed: 0.0874s/iter; left time: 2855.7627s
Epoch: 6 cost time: 4.06008243560791
Epoch: 6, Steps: 168 | Train Loss: 0.5161583 Vali Loss: 0.3554207 Test Loss: 0.5083272
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 7 | loss: 0.5696151
	speed: 0.0879s/iter; left time: 2854.8727s
Epoch: 7 cost time: 4.0621514320373535
Epoch: 7, Steps: 168 | Train Loss: 0.5159843 Vali Loss: 0.3534617 Test Loss: 0.5079893
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 8 | loss: 0.5709420
	speed: 0.0876s/iter; left time: 2832.8888s
Epoch: 8 cost time: 4.095158576965332
Epoch: 8, Steps: 168 | Train Loss: 0.5158625 Vali Loss: 0.3535451 Test Loss: 0.5078718
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1497
Traceback (most recent call last):
  File "run.py", line 161, in <module>
    exp.test(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 286, in test
    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 89, in visual
    plt.savefig(name, bbox_inches='tight')
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/pyplot.py", line 996, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/figure.py", line 3328, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2362, in print_figure
    result = print_method(
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2228, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 2823, in print_pdf
    file.close()
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 890, in close
    self.fh.close()
OSError: [Errno 122] Disk quota exceeded
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5383
val 703
test 1497
	iters: 100, epoch: 1 | loss: 0.4938209
	speed: 0.0265s/iter; left time: 888.8888s
Epoch: 1 cost time: 4.247314214706421
Epoch: 1, Steps: 168 | Train Loss: 0.5479623 Vali Loss: 0.3559936 Test Loss: 0.5123439
Validation loss decreased (inf --> 0.355994).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.4596878
	speed: 0.0887s/iter; left time: 2955.6236s
Epoch: 2 cost time: 4.192559719085693
Epoch: 2, Steps: 168 | Train Loss: 0.5191136 Vali Loss: 0.3537782 Test Loss: 0.5093209
Validation loss decreased (0.355994 --> 0.353778).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.4816093
	speed: 0.0883s/iter; left time: 2928.4897s
Epoch: 3 cost time: 4.082332611083984
Epoch: 3, Steps: 168 | Train Loss: 0.5167890 Vali Loss: 0.3526087 Test Loss: 0.5071617
Validation loss decreased (0.353778 --> 0.352609).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.5938712
	speed: 0.0876s/iter; left time: 2889.3935s
Epoch: 4 cost time: 4.05238938331604
Epoch: 4, Steps: 168 | Train Loss: 0.5162285 Vali Loss: 0.3546163 Test Loss: 0.5054071
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 5 | loss: 0.4580329
	speed: 0.0880s/iter; left time: 2889.7923s
Epoch: 5 cost time: 4.089018106460571
Epoch: 5, Steps: 168 | Train Loss: 0.5159975 Vali Loss: 0.3535392 Test Loss: 0.5090862
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 6 | loss: 0.5416057
	speed: 0.0882s/iter; left time: 2880.4772s
Epoch: 6 cost time: 4.082627058029175
Epoch: 6, Steps: 168 | Train Loss: 0.5161583 Vali Loss: 0.3554207 Test Loss: 0.5083272
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 7 | loss: 0.5696151
	speed: 0.0880s/iter; left time: 2859.7333s
Epoch: 7 cost time: 4.080869436264038
Epoch: 7, Steps: 168 | Train Loss: 0.5159843 Vali Loss: 0.3534617 Test Loss: 0.5079893
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 8 | loss: 0.5709420
	speed: 0.0877s/iter; left time: 2834.5307s
Epoch: 8 cost time: 4.117815732955933
Epoch: 8, Steps: 168 | Train Loss: 0.5158625 Vali Loss: 0.3535451 Test Loss: 0.5078718
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1497
test shape: (1497, 1, 96, 822) (1497, 1, 96, 822)
test shape: (1497, 96, 822) (1497, 96, 822)
mse:0.5071607232093811, mae:0.4150221347808838
>>>>>>>Overall time: 93 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_conv=4, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5383
val 703
test 1497
	iters: 100, epoch: 1 | loss: 0.4938209
	speed: 0.0268s/iter; left time: 898.0558s
Epoch: 1 cost time: 4.23258113861084
Epoch: 1, Steps: 168 | Train Loss: 0.5479623 Vali Loss: 0.3559936 Test Loss: 0.5123439
Validation loss decreased (inf --> 0.355994).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.4596878
	speed: 0.0915s/iter; left time: 3049.7278s
Epoch: 2 cost time: 4.11112642288208
Epoch: 2, Steps: 168 | Train Loss: 0.5191136 Vali Loss: 0.3537782 Test Loss: 0.5093209
Validation loss decreased (0.355994 --> 0.353778).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.4816093
	speed: 0.0890s/iter; left time: 2950.0734s
Epoch: 3 cost time: 4.046692609786987
Epoch: 3, Steps: 168 | Train Loss: 0.5167890 Vali Loss: 0.3526087 Test Loss: 0.5071617
Validation loss decreased (0.353778 --> 0.352609).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.5938712
	speed: 0.0899s/iter; left time: 2966.1915s
Epoch: 4 cost time: 4.081223249435425
Epoch: 4, Steps: 168 | Train Loss: 0.5162285 Vali Loss: 0.3546163 Test Loss: 0.5054071
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 5 | loss: 0.4580329
	speed: 0.0891s/iter; left time: 2926.3771s
Epoch: 5 cost time: 4.049039602279663
Epoch: 5, Steps: 168 | Train Loss: 0.5159975 Vali Loss: 0.3535392 Test Loss: 0.5090862
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 6 | loss: 0.5416057
	speed: 0.0891s/iter; left time: 2908.4789s
Epoch: 6 cost time: 4.035104513168335
Epoch: 6, Steps: 168 | Train Loss: 0.5161583 Vali Loss: 0.3554207 Test Loss: 0.5083272
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 7 | loss: 0.5696151
	speed: 0.0898s/iter; left time: 2917.5217s
Epoch: 7 cost time: 4.026404619216919
Epoch: 7, Steps: 168 | Train Loss: 0.5159843 Vali Loss: 0.3534617 Test Loss: 0.5079893
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 8 | loss: 0.5709420
	speed: 0.0893s/iter; left time: 2888.1620s
Epoch: 8 cost time: 4.060411691665649
Epoch: 8, Steps: 168 | Train Loss: 0.5158625 Vali Loss: 0.3535451 Test Loss: 0.5078718
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1497
test shape: (1497, 1, 96, 822) (1497, 1, 96, 822)
test shape: (1497, 96, 822) (1497, 96, 822)
mse:0.5071607232093811, mae:0.4150221347808838
>>>>>>>Overall time: 83 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
