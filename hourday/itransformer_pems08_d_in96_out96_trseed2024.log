Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=212, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=212, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems08_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5703
val 748
test 1589
	iters: 100, epoch: 1 | loss: 0.5248151
	speed: 0.0412s/iter; left time: 142.5029s
	iters: 200, epoch: 1 | loss: 0.4508001
	speed: 0.0329s/iter; left time: 110.5817s
	iters: 300, epoch: 1 | loss: 0.4498702
	speed: 0.0304s/iter; left time: 99.2760s
Epoch: 1 cost time: 12.241403341293335
Epoch: 1, Steps: 356 | Train Loss: 0.4810255 Vali Loss: 0.4034424 Test Loss: 0.7810917
Validation loss decreased (inf --> 0.403442).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.5023445
	speed: 0.1424s/iter; left time: 442.2395s
	iters: 200, epoch: 2 | loss: 0.4901083
	speed: 0.0307s/iter; left time: 92.1504s
	iters: 300, epoch: 2 | loss: 0.4989302
	speed: 0.0309s/iter; left time: 89.7628s
Epoch: 2 cost time: 11.419917106628418
Epoch: 2, Steps: 356 | Train Loss: 0.4722074 Vali Loss: 0.3990617 Test Loss: 0.7614744
Validation loss decreased (0.403442 --> 0.399062).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.5112000
	speed: 0.1442s/iter; left time: 396.2867s
	iters: 200, epoch: 3 | loss: 0.5083873
	speed: 0.0334s/iter; left time: 88.4661s
	iters: 300, epoch: 3 | loss: 0.3888247
	speed: 0.0353s/iter; left time: 89.9247s
Epoch: 3 cost time: 12.452939748764038
Epoch: 3, Steps: 356 | Train Loss: 0.4569932 Vali Loss: 0.3949060 Test Loss: 0.7607135
Validation loss decreased (0.399062 --> 0.394906).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.4656876
	speed: 0.1313s/iter; left time: 314.1273s
	iters: 200, epoch: 4 | loss: 0.4410686
	speed: 0.0305s/iter; left time: 69.9945s
	iters: 300, epoch: 4 | loss: 0.4591534
	speed: 0.0309s/iter; left time: 67.8226s
Epoch: 4 cost time: 11.341480016708374
Epoch: 4, Steps: 356 | Train Loss: 0.4429737 Vali Loss: 0.3953311 Test Loss: 0.7585545
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.4360915
	speed: 0.1342s/iter; left time: 273.4406s
	iters: 200, epoch: 5 | loss: 0.3890928
	speed: 0.0313s/iter; left time: 60.6100s
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=212, checkpoints='./checkpoints/', d_conv=4, d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=212, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems08_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5703
val 748
test 1589
	iters: 100, epoch: 1 | loss: 0.5248151
	speed: 0.0334s/iter; left time: 115.4380s
	iters: 200, epoch: 1 | loss: 0.4508001
	speed: 0.0294s/iter; left time: 98.7352s
	iters: 300, epoch: 1 | loss: 0.4498702
	speed: 0.0302s/iter; left time: 98.3733s
Epoch: 1 cost time: 11.055355548858643
Epoch: 1, Steps: 356 | Train Loss: 0.4810255 Vali Loss: 0.4034424 Test Loss: 0.7810917
Validation loss decreased (inf --> 0.403442).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.5023445
	speed: 0.1269s/iter; left time: 393.9169s
	iters: 200, epoch: 2 | loss: 0.4901083
	speed: 0.0304s/iter; left time: 91.2271s
	iters: 300, epoch: 2 | loss: 0.4989302
	speed: 0.0304s/iter; left time: 88.2532s
Epoch: 2 cost time: 11.057295322418213
Epoch: 2, Steps: 356 | Train Loss: 0.4722074 Vali Loss: 0.3990617 Test Loss: 0.7614744
Validation loss decreased (0.403442 --> 0.399062).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.5112000
	speed: 0.1249s/iter; left time: 343.2940s
	iters: 200, epoch: 3 | loss: 0.5083873
	speed: 0.0301s/iter; left time: 79.8618s
	iters: 300, epoch: 3 | loss: 0.3888247
	speed: 0.0303s/iter; left time: 77.3377s
Epoch: 3 cost time: 11.039495944976807
Epoch: 3, Steps: 356 | Train Loss: 0.4569932 Vali Loss: 0.3949060 Test Loss: 0.7607135
Validation loss decreased (0.399062 --> 0.394906).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.4656876
	speed: 0.1250s/iter; left time: 299.1144s
	iters: 200, epoch: 4 | loss: 0.4410686
	speed: 0.0302s/iter; left time: 69.2068s
	iters: 300, epoch: 4 | loss: 0.4591534
	speed: 0.0304s/iter; left time: 66.6131s
Epoch: 4 cost time: 11.057266473770142
Epoch: 4, Steps: 356 | Train Loss: 0.4429737 Vali Loss: 0.3953311 Test Loss: 0.7585545
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.4360915
	speed: 0.1250s/iter; left time: 254.6236s
	iters: 200, epoch: 5 | loss: 0.3890928
	speed: 0.0304s/iter; left time: 58.9798s
	iters: 300, epoch: 5 | loss: 0.4933858
	speed: 0.0303s/iter; left time: 55.7385s
Epoch: 5 cost time: 11.060011625289917
Epoch: 5, Steps: 356 | Train Loss: 0.4292766 Vali Loss: 0.3883750 Test Loss: 0.7657997
Validation loss decreased (0.394906 --> 0.388375).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.4690452
	speed: 0.1253s/iter; left time: 210.6752s
	iters: 200, epoch: 6 | loss: 0.3374923
	speed: 0.0301s/iter; left time: 47.6060s
	iters: 300, epoch: 6 | loss: 0.3681049
	speed: 0.0302s/iter; left time: 44.6583s
Epoch: 6 cost time: 11.018004894256592
Epoch: 6, Steps: 356 | Train Loss: 0.4178061 Vali Loss: 0.3928600 Test Loss: 0.7703459
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.4739182
	speed: 0.1252s/iter; left time: 165.8572s
	iters: 200, epoch: 7 | loss: 0.3563493
	speed: 0.0304s/iter; left time: 37.2885s
	iters: 300, epoch: 7 | loss: 0.3907768
	speed: 0.0304s/iter; left time: 34.1465s
Epoch: 7 cost time: 11.079846143722534
Epoch: 7, Steps: 356 | Train Loss: 0.4101165 Vali Loss: 0.3929230 Test Loss: 0.7752278
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3273430
	speed: 0.1250s/iter; left time: 121.1044s
	iters: 200, epoch: 8 | loss: 0.3812706
	speed: 0.0303s/iter; left time: 26.3616s
	iters: 300, epoch: 8 | loss: 0.3551531
	speed: 0.0304s/iter; left time: 23.3593s
Epoch: 8 cost time: 11.091360330581665
Epoch: 8, Steps: 356 | Train Loss: 0.4054817 Vali Loss: 0.3957863 Test Loss: 0.7777910
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems08_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1589
test shape: (1589, 1, 96, 212) (1589, 1, 96, 212)
test shape: (1589, 96, 212) (1589, 96, 212)
mse:0.7658000588417053, mae:0.4864197373390198
>>>>>>>Overall time: 159 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
