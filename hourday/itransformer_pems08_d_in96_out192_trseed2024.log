Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=212, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=212, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems08_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5607
val 652
test 1493
	iters: 100, epoch: 1 | loss: 0.5415049
	speed: 0.0365s/iter; left time: 124.3025s
	iters: 200, epoch: 1 | loss: 0.5847133
	speed: 0.0313s/iter; left time: 103.4826s
	iters: 300, epoch: 1 | loss: 0.5574172
	speed: 0.0315s/iter; left time: 100.9760s
Epoch: 1 cost time: 11.588905572891235
Epoch: 1, Steps: 350 | Train Loss: 0.5979087 Vali Loss: 0.4629941 Test Loss: 0.9310442
Validation loss decreased (inf --> 0.462994).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6307054
	speed: 0.1345s/iter; left time: 410.5113s
	iters: 200, epoch: 2 | loss: 0.5659847
	speed: 0.0327s/iter; left time: 96.4373s
	iters: 300, epoch: 2 | loss: 0.5934746
	speed: 0.0332s/iter; left time: 94.5352s
Epoch: 2 cost time: 12.01891565322876
Epoch: 2, Steps: 350 | Train Loss: 0.5921419 Vali Loss: 0.4514993 Test Loss: 0.9210345
Validation loss decreased (0.462994 --> 0.451499).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6014121
	speed: 0.1327s/iter; left time: 358.4276s
	iters: 200, epoch: 3 | loss: 0.6178468
	speed: 0.0331s/iter; left time: 86.2067s
	iters: 300, epoch: 3 | loss: 0.5945755
	speed: 0.0332s/iter; left time: 83.1426s
Epoch: 3 cost time: 11.97751760482788
Epoch: 3, Steps: 350 | Train Loss: 0.5777914 Vali Loss: 0.4442476 Test Loss: 0.9118298
Validation loss decreased (0.451499 --> 0.444248).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5360954
	speed: 0.1343s/iter; left time: 315.8561s
	iters: 200, epoch: 4 | loss: 0.4935686
	speed: 0.0326s/iter; left time: 73.4844s
	iters: 300, epoch: 4 | loss: 0.5443587
	speed: 0.0327s/iter; left time: 70.3668s
Epoch: 4 cost time: 11.818687438964844
Epoch: 4, Steps: 350 | Train Loss: 0.5664054 Vali Loss: 0.4380240 Test Loss: 0.9111211
Validation loss decreased (0.444248 --> 0.438024).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5675004
	speed: 0.1323s/iter; left time: 264.6676s
	iters: 200, epoch: 5 | loss: 0.5099304
	speed: 0.0327s/iter; left time: 62.1658s
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=212, checkpoints='./checkpoints/', d_conv=4, d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=212, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems08_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5607
val 652
test 1493
	iters: 100, epoch: 1 | loss: 0.5415049
	speed: 0.0346s/iter; left time: 117.6729s
	iters: 200, epoch: 1 | loss: 0.5847133
	speed: 0.0304s/iter; left time: 100.3293s
	iters: 300, epoch: 1 | loss: 0.5574172
	speed: 0.0308s/iter; left time: 98.6927s
Epoch: 1 cost time: 11.199207067489624
Epoch: 1, Steps: 350 | Train Loss: 0.5979087 Vali Loss: 0.4629941 Test Loss: 0.9310442
Validation loss decreased (inf --> 0.462994).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6307054
	speed: 0.1255s/iter; left time: 382.7691s
	iters: 200, epoch: 2 | loss: 0.5659847
	speed: 0.0309s/iter; left time: 91.1598s
	iters: 300, epoch: 2 | loss: 0.5934746
	speed: 0.0310s/iter; left time: 88.3600s
Epoch: 2 cost time: 11.06489634513855
Epoch: 2, Steps: 350 | Train Loss: 0.5921419 Vali Loss: 0.4514993 Test Loss: 0.9210345
Validation loss decreased (0.462994 --> 0.451499).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6014121
	speed: 0.1244s/iter; left time: 335.9481s
	iters: 200, epoch: 3 | loss: 0.6178468
	speed: 0.0306s/iter; left time: 79.4979s
	iters: 300, epoch: 3 | loss: 0.5945755
	speed: 0.0307s/iter; left time: 76.8031s
Epoch: 3 cost time: 11.004284381866455
Epoch: 3, Steps: 350 | Train Loss: 0.5777914 Vali Loss: 0.4442476 Test Loss: 0.9118298
Validation loss decreased (0.451499 --> 0.444248).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5360954
	speed: 0.1235s/iter; left time: 290.4605s
	iters: 200, epoch: 4 | loss: 0.4935686
	speed: 0.0310s/iter; left time: 69.7257s
	iters: 300, epoch: 4 | loss: 0.5443587
	speed: 0.0311s/iter; left time: 66.8799s
Epoch: 4 cost time: 11.14263916015625
Epoch: 4, Steps: 350 | Train Loss: 0.5664054 Vali Loss: 0.4380240 Test Loss: 0.9111211
Validation loss decreased (0.444248 --> 0.438024).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5675004
	speed: 0.1246s/iter; left time: 249.3004s
	iters: 200, epoch: 5 | loss: 0.5099304
	speed: 0.0310s/iter; left time: 59.0073s
	iters: 300, epoch: 5 | loss: 0.5069726
	speed: 0.0315s/iter; left time: 56.7844s
Epoch: 5 cost time: 11.253043174743652
Epoch: 5, Steps: 350 | Train Loss: 0.5559752 Vali Loss: 0.4388250 Test Loss: 0.9130272
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.4516250
	speed: 0.1241s/iter; left time: 204.8315s
	iters: 200, epoch: 6 | loss: 0.5291645
	speed: 0.0319s/iter; left time: 49.5477s
	iters: 300, epoch: 6 | loss: 0.4970203
	speed: 0.0320s/iter; left time: 46.4350s
Epoch: 6 cost time: 11.368776798248291
Epoch: 6, Steps: 350 | Train Loss: 0.5462846 Vali Loss: 0.4446892 Test Loss: 0.9226969
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5216398
	speed: 0.1244s/iter; left time: 161.8594s
	iters: 200, epoch: 7 | loss: 0.5188874
	speed: 0.0318s/iter; left time: 38.2394s
	iters: 300, epoch: 7 | loss: 0.5049796
	speed: 0.0318s/iter; left time: 35.0620s
Epoch: 7 cost time: 11.43144154548645
Epoch: 7, Steps: 350 | Train Loss: 0.5383266 Vali Loss: 0.4450890 Test Loss: 0.9306974
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems08_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1493
test shape: (1493, 1, 192, 212) (1493, 1, 192, 212)
test shape: (1493, 192, 212) (1493, 192, 212)
mse:0.9111219048500061, mae:0.5537499785423279
>>>>>>>Overall time: 142 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
