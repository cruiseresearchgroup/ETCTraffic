Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=151, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems03_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.7331986
	speed: 0.0359s/iter; left time: 111.8134s
	iters: 200, epoch: 1 | loss: 0.6925080
	speed: 0.0320s/iter; left time: 96.2947s
	iters: 300, epoch: 1 | loss: 0.7131659
	speed: 0.0324s/iter; left time: 94.2362s
Epoch: 1 cost time: 10.802087306976318
Epoch: 1, Steps: 321 | Train Loss: 0.7874524 Vali Loss: 0.6621965 Test Loss: 0.9834693
Validation loss decreased (inf --> 0.662196).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.8110244
	speed: 0.1133s/iter; left time: 316.2437s
	iters: 200, epoch: 2 | loss: 0.7993837
	speed: 0.0301s/iter; left time: 80.9447s
	iters: 300, epoch: 2 | loss: 0.7490599
	speed: 0.0306s/iter; left time: 79.3350s
Epoch: 2 cost time: 10.17491888999939
Epoch: 2, Steps: 321 | Train Loss: 0.7785533 Vali Loss: 0.6657912 Test Loss: 1.0006751
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.7526675
	speed: 0.1087s/iter; left time: 268.4207s
	iters: 200, epoch: 3 | loss: 0.8745239
	speed: 0.0306s/iter; left time: 72.4864s
	iters: 300, epoch: 3 | loss: 0.6721428
	speed: 0.0304s/iter; left time: 69.0125s
Epoch: 3 cost time: 10.220726490020752
Epoch: 3, Steps: 321 | Train Loss: 0.7649426 Vali Loss: 0.6581154 Test Loss: 0.9718471
Validation loss decreased (0.662196 --> 0.658115).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.7829978
	speed: 0.1102s/iter; left time: 236.6607s
	iters: 200, epoch: 4 | loss: 0.7161474
	speed: 0.0304s/iter; left time: 62.3357s
	iters: 300, epoch: 4 | loss: 0.7242974
	speed: 0.0304s/iter; left time: 59.2978s
Epoch: 4 cost time: 10.261366844177246
Epoch: 4, Steps: 321 | Train Loss: 0.7461641 Vali Loss: 0.6521981 Test Loss: 0.9672731
Validation loss decreased (0.658115 --> 0.652198).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6981614
	speed: 0.1089s/iter; left time: 199.0446s
	iters: 200, epoch: 5 | loss: 0.7385810
	speed: 0.0305s/iter; left time: 52.7396s
	iters: 300, epoch: 5 | loss: 0.7411302
	speed: 0.0304s/iter; left time: 49.4933s
Epoch: 5 cost time: 10.205394744873047
Epoch: 5, Steps: 321 | Train Loss: 0.7333285 Vali Loss: 0.6587454 Test Loss: 0.9624772
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.7368349
	speed: 0.1092s/iter; left time: 164.4916s
	iters: 200, epoch: 6 | loss: 0.7497169
	speed: 0.0304s/iter; left time: 42.7784s
	iters: 300, epoch: 6 | loss: 0.6818847
	speed: 0.0308s/iter; left time: 40.2731s
Epoch: 6 cost time: 10.252094745635986
Epoch: 6, Steps: 321 | Train Loss: 0.7216985 Vali Loss: 0.6591178 Test Loss: 0.9667332
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.6186600
	speed: 0.1085s/iter; left time: 128.5186s
	iters: 200, epoch: 7 | loss: 0.7693895
	speed: 0.0306s/iter; left time: 33.2213s
	iters: 300, epoch: 7 | loss: 0.7748805
	speed: 0.0303s/iter; left time: 29.8644s
Epoch: 7 cost time: 10.1640625
Epoch: 7, Steps: 321 | Train Loss: 0.7132586 Vali Loss: 0.6651067 Test Loss: 0.9680244
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems03_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 151) (1257, 1, 336, 151)
test shape: (1257, 336, 151) (1257, 336, 151)
mse:0.9672741293907166, mae:0.5791485905647278
>>>>>>>Overall time: 130 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=151, checkpoints='./checkpoints/', d_conv=4, d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=151, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems03_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.7331986
	speed: 0.0352s/iter; left time: 109.4987s
	iters: 200, epoch: 1 | loss: 0.6925080
	speed: 0.0304s/iter; left time: 91.6549s
	iters: 300, epoch: 1 | loss: 0.7131659
	speed: 0.0304s/iter; left time: 88.6383s
Epoch: 1 cost time: 10.324751615524292
Epoch: 1, Steps: 321 | Train Loss: 0.7874524 Vali Loss: 0.6621965 Test Loss: 0.9834693
Validation loss decreased (inf --> 0.662196).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.8110244
	speed: 0.1068s/iter; left time: 297.8598s
	iters: 200, epoch: 2 | loss: 0.7993837
	speed: 0.0305s/iter; left time: 82.0312s
	iters: 300, epoch: 2 | loss: 0.7490599
	speed: 0.0304s/iter; left time: 78.7129s
Epoch: 2 cost time: 10.132466077804565
Epoch: 2, Steps: 321 | Train Loss: 0.7785533 Vali Loss: 0.6657912 Test Loss: 1.0006751
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.7526675
	speed: 0.1063s/iter; left time: 262.3798s
	iters: 200, epoch: 3 | loss: 0.8745239
	speed: 0.0307s/iter; left time: 72.8431s
	iters: 300, epoch: 3 | loss: 0.6721428
	speed: 0.0304s/iter; left time: 68.9842s
Epoch: 3 cost time: 10.159563541412354
Epoch: 3, Steps: 321 | Train Loss: 0.7649426 Vali Loss: 0.6581154 Test Loss: 0.9718471
Validation loss decreased (0.662196 --> 0.658115).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.7829978
	speed: 0.1059s/iter; left time: 227.4916s
	iters: 200, epoch: 4 | loss: 0.7161474
	speed: 0.0304s/iter; left time: 62.2696s
	iters: 300, epoch: 4 | loss: 0.7242974
	speed: 0.0304s/iter; left time: 59.3123s
Epoch: 4 cost time: 10.122529983520508
Epoch: 4, Steps: 321 | Train Loss: 0.7461641 Vali Loss: 0.6521981 Test Loss: 0.9672731
Validation loss decreased (0.658115 --> 0.652198).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6981614
	speed: 0.1070s/iter; left time: 195.5676s
	iters: 200, epoch: 5 | loss: 0.7385810
	speed: 0.0305s/iter; left time: 52.6495s
	iters: 300, epoch: 5 | loss: 0.7411302
	speed: 0.0304s/iter; left time: 49.4736s
Epoch: 5 cost time: 10.134614944458008
Epoch: 5, Steps: 321 | Train Loss: 0.7333285 Vali Loss: 0.6587454 Test Loss: 0.9624772
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.7368349
	speed: 0.1060s/iter; left time: 159.6169s
	iters: 200, epoch: 6 | loss: 0.7497169
	speed: 0.0302s/iter; left time: 42.4203s
	iters: 300, epoch: 6 | loss: 0.6818847
	speed: 0.0303s/iter; left time: 39.6036s
Epoch: 6 cost time: 10.057714462280273
Epoch: 6, Steps: 321 | Train Loss: 0.7216985 Vali Loss: 0.6591178 Test Loss: 0.9667332
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.6186600
	speed: 0.1057s/iter; left time: 125.2937s
	iters: 200, epoch: 7 | loss: 0.7693895
	speed: 0.0305s/iter; left time: 33.0899s
	iters: 300, epoch: 7 | loss: 0.7748805
	speed: 0.0302s/iter; left time: 29.7369s
Epoch: 7 cost time: 10.076171159744263
Epoch: 7, Steps: 321 | Train Loss: 0.7132586 Vali Loss: 0.6651067 Test Loss: 0.9680244
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems03_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 151) (1257, 1, 336, 151)
test shape: (1257, 336, 151) (1257, 336, 151)
mse:0.9672741293907166, mae:0.5791485905647278
>>>>>>>Overall time: 127 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
