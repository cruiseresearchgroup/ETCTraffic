Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116408127.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116443174.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.7072890
	speed: 0.0348s/iter; left time: 1143.6102s
Epoch: 1 cost time: 5.506726264953613
Epoch: 1, Steps: 165 | Train Loss: 0.6399178 Vali Loss: 0.4327111 Test Loss: 0.6151044
Validation loss decreased (inf --> 0.432711).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.5745237
	speed: 0.1133s/iter; left time: 3708.0826s
Epoch: 2 cost time: 5.30773401260376
Epoch: 2, Steps: 165 | Train Loss: 0.6134661 Vali Loss: 0.4263140 Test Loss: 0.6104624
Validation loss decreased (0.432711 --> 0.426314).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.6087394
	speed: 0.1135s/iter; left time: 3698.0395s
Epoch: 3 cost time: 5.373653888702393
Epoch: 3, Steps: 165 | Train Loss: 0.6112371 Vali Loss: 0.4282249 Test Loss: 0.6115874
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.5304659
	speed: 0.1132s/iter; left time: 3669.5380s
Epoch: 4 cost time: 5.284941911697388
Epoch: 4, Steps: 165 | Train Loss: 0.6110117 Vali Loss: 0.4299121 Test Loss: 0.6119747
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.4925324
	speed: 0.1133s/iter; left time: 3654.1222s
Epoch: 5 cost time: 5.324624300003052
Epoch: 5, Steps: 165 | Train Loss: 0.6105616 Vali Loss: 0.4279727 Test Loss: 0.6098809
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.5331746
	speed: 0.1146s/iter; left time: 3674.4244s
Epoch: 6 cost time: 5.339629173278809
Epoch: 6, Steps: 165 | Train Loss: 0.6108949 Vali Loss: 0.4269508 Test Loss: 0.6094996
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.5475950
	speed: 0.1132s/iter; left time: 3611.4516s
Epoch: 7 cost time: 5.307171821594238
Epoch: 7, Steps: 165 | Train Loss: 0.6107841 Vali Loss: 0.4275763 Test Loss: 0.6097618
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
Traceback (most recent call last):
  File "run.py", line 161, in <module>
    exp.test(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 286, in test
    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 89, in visual
    plt.savefig(name, bbox_inches='tight')
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/pyplot.py", line 996, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/figure.py", line 3328, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2362, in print_figure
    result = print_method(
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2228, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 2823, in print_pdf
    file.close()
  File "/jobfs/116444158.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 890, in close
    self.fh.close()
OSError: [Errno 122] Disk quota exceeded
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.7072890
	speed: 0.0347s/iter; left time: 1143.0873s
Epoch: 1 cost time: 5.4840734004974365
Epoch: 1, Steps: 165 | Train Loss: 0.6399178 Vali Loss: 0.4327111 Test Loss: 0.6151044
Validation loss decreased (inf --> 0.432711).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.5745237
	speed: 0.1139s/iter; left time: 3730.1773s
Epoch: 2 cost time: 5.357874870300293
Epoch: 2, Steps: 165 | Train Loss: 0.6134661 Vali Loss: 0.4263140 Test Loss: 0.6104624
Validation loss decreased (0.432711 --> 0.426314).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.6087394
	speed: 0.1145s/iter; left time: 3727.7526s
Epoch: 3 cost time: 5.304334878921509
Epoch: 3, Steps: 165 | Train Loss: 0.6112371 Vali Loss: 0.4282249 Test Loss: 0.6115874
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.5304659
	speed: 0.1136s/iter; left time: 3682.8464s
Epoch: 4 cost time: 5.367291688919067
Epoch: 4, Steps: 165 | Train Loss: 0.6110117 Vali Loss: 0.4299121 Test Loss: 0.6119747
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.4925324
	speed: 0.1136s/iter; left time: 3661.9683s
Epoch: 5 cost time: 5.373949766159058
Epoch: 5, Steps: 165 | Train Loss: 0.6105616 Vali Loss: 0.4279727 Test Loss: 0.6098809
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.5331746
	speed: 0.1146s/iter; left time: 3676.9242s
Epoch: 6 cost time: 5.378405570983887
Epoch: 6, Steps: 165 | Train Loss: 0.6108949 Vali Loss: 0.4269508 Test Loss: 0.6094996
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.5475950
	speed: 0.1141s/iter; left time: 3642.3970s
Epoch: 7 cost time: 5.348589897155762
Epoch: 7, Steps: 165 | Train Loss: 0.6107841 Vali Loss: 0.4275763 Test Loss: 0.6097618
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
test shape: (1401, 1, 192, 822) (1401, 1, 192, 822)
test shape: (1401, 192, 822) (1401, 192, 822)
mse:0.6104626059532166, mae:0.4830779731273651
>>>>>>>Overall time: 105 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_conv=4, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems04_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.7072890
	speed: 0.0354s/iter; left time: 1164.3038s
Epoch: 1 cost time: 5.529229640960693
Epoch: 1, Steps: 165 | Train Loss: 0.6399178 Vali Loss: 0.4327111 Test Loss: 0.6151044
Validation loss decreased (inf --> 0.432711).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.5745237
	speed: 0.1144s/iter; left time: 3746.1117s
Epoch: 2 cost time: 5.316002368927002
Epoch: 2, Steps: 165 | Train Loss: 0.6134661 Vali Loss: 0.4263140 Test Loss: 0.6104624
Validation loss decreased (0.432711 --> 0.426314).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.6087394
	speed: 0.1139s/iter; left time: 3710.4799s
Epoch: 3 cost time: 5.313589096069336
Epoch: 3, Steps: 165 | Train Loss: 0.6112371 Vali Loss: 0.4282249 Test Loss: 0.6115874
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.5304659
	speed: 0.1146s/iter; left time: 3715.0897s
Epoch: 4 cost time: 5.254206895828247
Epoch: 4, Steps: 165 | Train Loss: 0.6110117 Vali Loss: 0.4299121 Test Loss: 0.6119747
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.4925324
	speed: 0.1153s/iter; left time: 3716.2180s
Epoch: 5 cost time: 5.3222336769104
Epoch: 5, Steps: 165 | Train Loss: 0.6105616 Vali Loss: 0.4279727 Test Loss: 0.6098809
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.5331746
	speed: 0.1151s/iter; left time: 3692.9269s
Epoch: 6 cost time: 5.394406795501709
Epoch: 6, Steps: 165 | Train Loss: 0.6108949 Vali Loss: 0.4269508 Test Loss: 0.6094996
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.5475950
	speed: 0.1139s/iter; left time: 3636.0197s
Epoch: 7 cost time: 5.241459131240845
Epoch: 7, Steps: 165 | Train Loss: 0.6107841 Vali Loss: 0.4275763 Test Loss: 0.6097618
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
test shape: (1401, 1, 192, 822) (1401, 1, 192, 822)
test shape: (1401, 192, 822) (1401, 192, 822)
mse:0.6104626059532166, mae:0.4830779731273651
>>>>>>>Overall time: 93 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
