Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=151, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems03_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.6546179
	speed: 0.0372s/iter; left time: 119.1076s
	iters: 200, epoch: 1 | loss: 0.6728693
	speed: 0.0319s/iter; left time: 98.8937s
	iters: 300, epoch: 1 | loss: 0.7075127
	speed: 0.0320s/iter; left time: 95.9372s
Epoch: 1 cost time: 11.159968137741089
Epoch: 1, Steps: 330 | Train Loss: 0.6805409 Vali Loss: 0.5703621 Test Loss: 0.7983320
Validation loss decreased (inf --> 0.570362).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.7608742
	speed: 0.1159s/iter; left time: 332.6064s
	iters: 200, epoch: 2 | loss: 0.7364553
	speed: 0.0317s/iter; left time: 87.9329s
	iters: 300, epoch: 2 | loss: 0.6784837
	speed: 0.0321s/iter; left time: 85.8679s
Epoch: 2 cost time: 10.933025121688843
Epoch: 2, Steps: 330 | Train Loss: 0.6696853 Vali Loss: 0.5828699 Test Loss: 0.8121336
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6171347
	speed: 0.1171s/iter; left time: 297.5487s
	iters: 200, epoch: 3 | loss: 0.5443937
	speed: 0.0349s/iter; left time: 85.1573s
	iters: 300, epoch: 3 | loss: 0.6254634
	speed: 0.0324s/iter; left time: 75.7657s
Epoch: 3 cost time: 11.48733639717102
Epoch: 3, Steps: 330 | Train Loss: 0.6535451 Vali Loss: 0.5547060 Test Loss: 0.7827322
Validation loss decreased (0.570362 --> 0.554706).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.6819764
	speed: 0.1217s/iter; left time: 269.0674s
	iters: 200, epoch: 4 | loss: 0.6162218
	speed: 0.0369s/iter; left time: 77.8171s
	iters: 300, epoch: 4 | loss: 0.5745662
	speed: 0.0329s/iter; left time: 66.1883s
Epoch: 4 cost time: 12.378237962722778
Epoch: 4, Steps: 330 | Train Loss: 0.6369704 Vali Loss: 0.5584639 Test Loss: 0.7764904
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6358932
	speed: 0.1221s/iter; left time: 229.5797s
	iters: 200, epoch: 5 | loss: 0.5698929
	speed: 0.0381s/iter; left time: 67.9222s
	iters: 300, epoch: 5 | loss: 0.5693893
	speed: 0.0324s/iter; left time: 54.3936s
Epoch: 5 cost time: 12.24836277961731
Epoch: 5, Steps: 330 | Train Loss: 0.6233551 Vali Loss: 0.5532750 Test Loss: 0.7806087
Validation loss decreased (0.554706 --> 0.553275).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.6242043
	speed: 0.1190s/iter; left time: 184.4970s
	iters: 200, epoch: 6 | loss: 0.6545070
	speed: 0.0342s/iter; left time: 49.5649s
	iters: 300, epoch: 6 | loss: 0.4926941
	speed: 0.0346s/iter; left time: 46.6932s
Epoch: 6 cost time: 11.881362676620483
Epoch: 6, Steps: 330 | Train Loss: 0.6118081 Vali Loss: 0.5606561 Test Loss: 0.7791026
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5553870
	speed: 0.1192s/iter; left time: 145.5217s
	iters: 200, epoch: 7 | loss: 0.7227005
	speed: 0.0341s/iter; left time: 38.2586s
	iters: 300, epoch: 7 | loss: 0.5445884
	speed: 0.0323s/iter; left time: 32.9727s
Epoch: 7 cost time: 11.450709342956543
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=151, checkpoints='./checkpoints/', d_conv=4, d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=151, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems03_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.6546179
	speed: 0.0346s/iter; left time: 110.9048s
	iters: 200, epoch: 1 | loss: 0.6728693
	speed: 0.0303s/iter; left time: 93.8798s
	iters: 300, epoch: 1 | loss: 0.7075127
	speed: 0.0303s/iter; left time: 91.0251s
Epoch: 1 cost time: 10.51453948020935
Epoch: 1, Steps: 330 | Train Loss: 0.6805409 Vali Loss: 0.5703621 Test Loss: 0.7983320
Validation loss decreased (inf --> 0.570362).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.7608742
	speed: 0.1130s/iter; left time: 324.4370s
	iters: 200, epoch: 2 | loss: 0.7364553
	speed: 0.0302s/iter; left time: 83.6884s
	iters: 300, epoch: 2 | loss: 0.6784837
	speed: 0.0303s/iter; left time: 81.0075s
Epoch: 2 cost time: 10.346170663833618
Epoch: 2, Steps: 330 | Train Loss: 0.6696853 Vali Loss: 0.5828699 Test Loss: 0.8121336
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6171347
	speed: 0.1107s/iter; left time: 281.3632s
	iters: 200, epoch: 3 | loss: 0.5443937
	speed: 0.0305s/iter; left time: 74.3737s
	iters: 300, epoch: 3 | loss: 0.6254634
	speed: 0.0301s/iter; left time: 70.4700s
Epoch: 3 cost time: 10.318295001983643
Epoch: 3, Steps: 330 | Train Loss: 0.6535451 Vali Loss: 0.5547060 Test Loss: 0.7827322
Validation loss decreased (0.570362 --> 0.554706).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.6819764
	speed: 0.1096s/iter; left time: 242.2680s
	iters: 200, epoch: 4 | loss: 0.6162218
	speed: 0.0300s/iter; left time: 63.3614s
	iters: 300, epoch: 4 | loss: 0.5745662
	speed: 0.0300s/iter; left time: 60.3646s
Epoch: 4 cost time: 10.245192766189575
Epoch: 4, Steps: 330 | Train Loss: 0.6369704 Vali Loss: 0.5584639 Test Loss: 0.7764904
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6358932
	speed: 0.1103s/iter; left time: 207.4974s
	iters: 200, epoch: 5 | loss: 0.5698929
	speed: 0.0300s/iter; left time: 53.4680s
	iters: 300, epoch: 5 | loss: 0.5693893
	speed: 0.0303s/iter; left time: 50.9714s
Epoch: 5 cost time: 10.340081691741943
Epoch: 5, Steps: 330 | Train Loss: 0.6233551 Vali Loss: 0.5532750 Test Loss: 0.7806087
Validation loss decreased (0.554706 --> 0.553275).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.6242043
	speed: 0.1109s/iter; left time: 171.9817s
	iters: 200, epoch: 6 | loss: 0.6545070
	speed: 0.0305s/iter; left time: 44.2257s
	iters: 300, epoch: 6 | loss: 0.4926941
	speed: 0.0304s/iter; left time: 41.0801s
Epoch: 6 cost time: 10.359599351882935
Epoch: 6, Steps: 330 | Train Loss: 0.6118081 Vali Loss: 0.5606561 Test Loss: 0.7791026
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5553870
	speed: 0.1108s/iter; left time: 135.2603s
	iters: 200, epoch: 7 | loss: 0.7227005
	speed: 0.0303s/iter; left time: 33.9426s
	iters: 300, epoch: 7 | loss: 0.5445884
	speed: 0.0304s/iter; left time: 31.0576s
Epoch: 7 cost time: 10.381623029708862
Epoch: 7, Steps: 330 | Train Loss: 0.6034295 Vali Loss: 0.5614703 Test Loss: 0.7829133
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.5578696
	speed: 0.1098s/iter; left time: 97.8669s
	iters: 200, epoch: 8 | loss: 0.5466064
	speed: 0.0304s/iter; left time: 24.0257s
	iters: 300, epoch: 8 | loss: 0.6429520
	speed: 0.0303s/iter; left time: 20.9687s
Epoch: 8 cost time: 10.301472187042236
Epoch: 8, Steps: 330 | Train Loss: 0.5971010 Vali Loss: 0.5698097 Test Loss: 0.7826722
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems03_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
test shape: (1401, 1, 192, 151) (1401, 1, 192, 151)
test shape: (1401, 192, 151) (1401, 192, 151)
mse:0.7806099653244019, mae:0.4998794198036194
>>>>>>>Overall time: 147 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
