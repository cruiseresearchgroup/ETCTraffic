Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5393
train 5249
train 5489
val 621
val 477
val 717
test 1288
test 1432
test 1528
	iters: 100, epoch: 1 | loss: 0.5374539
	speed: 0.3031s/iter; left time: 1009.7805s
	iters: 100, epoch: 1 | loss: 0.6154156
	speed: 0.3080s/iter; left time: 1007.3425s
	iters: 100, epoch: 1 | loss: 0.7208552
	speed: 0.3329s/iter; left time: 1058.9141s
	iters: 200, epoch: 1 | loss: 0.5508391
	speed: 0.2983s/iter; left time: 963.8650s
	iters: 200, epoch: 1 | loss: 0.6520887
	speed: 0.3031s/iter; left time: 961.0536s
	iters: 200, epoch: 1 | loss: 0.8416574
	speed: 0.3279s/iter; left time: 1010.1187s
	iters: 300, epoch: 1 | loss: 0.5242283
	speed: 0.2985s/iter; left time: 934.5531s
	iters: 300, epoch: 1 | loss: 0.7127319
	speed: 0.3032s/iter; left time: 931.0323s
	iters: 300, epoch: 1 | loss: 0.7726676
	speed: 0.3270s/iter; left time: 974.6870s
Epoch: 1 cost time: 102.75341701507568
Epoch: 1 cost time: 102.91928315162659
Epoch: 1 cost time: 108.09353566169739
Epoch: 1, Steps: 343 | Train Loss: 0.5303340 Vali Loss: 0.5462819 Test Loss: 1.3727021
Validation loss decreased (inf --> 0.546282).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 337 | Train Loss: 0.6692494 Vali Loss: 0.6930244 Test Loss: 1.6881812
Validation loss decreased (inf --> 0.693024).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 328 | Train Loss: 0.7854004 Vali Loss: 0.8454524 Test Loss: 2.0000029
Validation loss decreased (inf --> 0.845452).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.5312706
	speed: 0.6623s/iter; left time: 1979.0936s
	iters: 100, epoch: 2 | loss: 0.5548610
	speed: 0.6684s/iter; left time: 1961.0078s
	iters: 100, epoch: 2 | loss: 0.8205249
	speed: 0.6744s/iter; left time: 1924.1111s
	iters: 200, epoch: 2 | loss: 0.4976090
	speed: 0.2983s/iter; left time: 861.5758s
	iters: 200, epoch: 2 | loss: 0.6452782
	speed: 0.3032s/iter; left time: 859.3899s
	iters: 200, epoch: 2 | loss: 0.8353567
	speed: 0.3252s/iter; left time: 895.1866s
	iters: 300, epoch: 2 | loss: 0.5698890
	speed: 0.2983s/iter; left time: 831.7956s
	iters: 300, epoch: 2 | loss: 0.7281306
	speed: 0.3034s/iter; left time: 829.4335s
Epoch: 2 cost time: 102.64410853385925
Epoch: 2 cost time: 102.55905246734619
	iters: 300, epoch: 2 | loss: 0.7758309
	speed: 0.3254s/iter; left time: 863.2545s
Epoch: 2 cost time: 107.13556599617004
Epoch: 2, Steps: 343 | Train Loss: 0.5070989 Vali Loss: 0.5402326 Test Loss: 1.3731332
Validation loss decreased (0.546282 --> 0.540233).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 337 | Train Loss: 0.6458111 Vali Loss: 0.6854712 Test Loss: 1.7115531
Validation loss decreased (0.693024 --> 0.685471).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 328 | Train Loss: 0.7627029 Vali Loss: 0.8380193 Test Loss: 1.9650997
Validation loss decreased (0.845452 --> 0.838019).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.4148667
	speed: 0.6610s/iter; left time: 1748.4211s
	iters: 100, epoch: 3 | loss: 0.5258105
	speed: 0.6719s/iter; left time: 1745.0016s
	iters: 100, epoch: 3 | loss: 0.7202443
	speed: 0.6854s/iter; left time: 1730.6041s
	iters: 200, epoch: 3 | loss: 0.4208497
	speed: 0.2984s/iter; left time: 759.3324s
	iters: 200, epoch: 3 | loss: 0.5797976
	speed: 0.3031s/iter; left time: 756.9518s
	iters: 200, epoch: 3 | loss: 0.6744499
	speed: 0.3261s/iter; left time: 790.7954s
	iters: 300, epoch: 3 | loss: 0.4783379
	speed: 0.2984s/iter; left time: 729.6857s
	iters: 300, epoch: 3 | loss: 0.5522550
	speed: 0.3034s/iter; left time: 727.1811s
Epoch: 3 cost time: 102.64081454277039
Epoch: 3 cost time: 102.55600166320801
	iters: 300, epoch: 3 | loss: 0.6336148
	speed: 0.3266s/iter; left time: 759.2654s
Epoch: 3 cost time: 107.4749345779419
Epoch: 3, Steps: 343 | Train Loss: 0.4853129 Vali Loss: 0.5208250 Test Loss: 1.3699170
Validation loss decreased (0.540233 --> 0.520825).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 337 | Train Loss: 0.6162110 Vali Loss: 0.6780807 Test Loss: 1.6982517
Validation loss decreased (0.685471 --> 0.678081).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 328 | Train Loss: 0.7389889 Vali Loss: 0.8291610 Test Loss: 1.9797181
Validation loss decreased (0.838019 --> 0.829161).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5147137
	speed: 0.6630s/iter; left time: 1526.2271s
	iters: 100, epoch: 4 | loss: 0.6493328
	speed: 0.6684s/iter; left time: 1510.6626s
	iters: 100, epoch: 4 | loss: 0.8065909
	speed: 0.6827s/iter; left time: 1499.8153s
	iters: 200, epoch: 4 | loss: 0.4524071
	speed: 0.2984s/iter; left time: 657.0935s
	iters: 200, epoch: 4 | loss: 0.5101603
	speed: 0.3033s/iter; left time: 655.1060s
	iters: 200, epoch: 4 | loss: 0.8364941
	speed: 0.3263s/iter; left time: 684.2021s
	iters: 300, epoch: 4 | loss: 0.4264497
	speed: 0.2985s/iter; left time: 627.3664s
	iters: 300, epoch: 4 | loss: 0.5857759
	speed: 0.3034s/iter; left time: 624.9346s
Epoch: 4 cost time: 102.67673563957214
Epoch: 4 cost time: 102.57526206970215
	iters: 300, epoch: 4 | loss: 0.6569890
	speed: 0.3265s/iter; left time: 652.0817s
Epoch: 4, Steps: 343 | Train Loss: 0.4671129 Vali Loss: 0.5213310 Test Loss: 1.3902489
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
Epoch: 4 cost time: 107.47156739234924
Epoch: 4, Steps: 337 | Train Loss: 0.5954086 Vali Loss: 0.6755006 Test Loss: 1.7057939
Validation loss decreased (0.678081 --> 0.675501).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3982726
	speed: 0.6629s/iter; left time: 1298.6537s
Epoch: 4, Steps: 328 | Train Loss: 0.7172692 Vali Loss: 0.8280061 Test Loss: 1.9843184
Validation loss decreased (0.829161 --> 0.828006).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5706328
	speed: 0.6669s/iter; left time: 1282.4623s
	iters: 200, epoch: 5 | loss: 0.4241217
	speed: 0.2984s/iter; left time: 554.7908s
	iters: 100, epoch: 5 | loss: 0.7057213
	speed: 0.6885s/iter; left time: 1286.8781s
	iters: 200, epoch: 5 | loss: 0.5267957
	speed: 0.3032s/iter; left time: 552.7860s
	iters: 300, epoch: 5 | loss: 0.3787919
	speed: 0.2985s/iter; left time: 525.0752s
	iters: 200, epoch: 5 | loss: 0.7043529
	speed: 0.3260s/iter; left time: 576.7050s
	iters: 300, epoch: 5 | loss: 0.6611917
	speed: 0.3033s/iter; left time: 522.5732s
Epoch: 5 cost time: 102.71331429481506
Epoch: 5 cost time: 102.5689868927002
Epoch: 5, Steps: 343 | Train Loss: 0.4537562 Vali Loss: 0.5191166 Test Loss: 1.3772471
Validation loss decreased (0.520825 --> 0.519117).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 300, epoch: 5 | loss: 0.7886059
	speed: 0.3265s/iter; left time: 544.9234s
Epoch: 5, Steps: 337 | Train Loss: 0.5789127 Vali Loss: 0.6714928 Test Loss: 1.7166827
Validation loss decreased (0.675501 --> 0.671493).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 107.44520807266235
	iters: 100, epoch: 6 | loss: 0.4577927
	speed: 0.6585s/iter; left time: 1064.1979s
Epoch: 5, Steps: 328 | Train Loss: 0.6967746 Vali Loss: 0.8321493 Test Loss: 1.9834007
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5729499
	speed: 0.6566s/iter; left time: 1041.3294s
	iters: 200, epoch: 6 | loss: 0.4186025
	speed: 0.2984s/iter; left time: 452.3281s
	iters: 200, epoch: 6 | loss: 0.4952581
	speed: 0.3008s/iter; left time: 446.9808s
	iters: 100, epoch: 6 | loss: 0.6145142
	speed: 0.6705s/iter; left time: 1033.2015s
	iters: 300, epoch: 6 | loss: 0.4150076
	speed: 0.2984s/iter; left time: 422.5933s
	iters: 300, epoch: 6 | loss: 0.5337827
	speed: 0.3009s/iter; left time: 417.0443s
	iters: 200, epoch: 6 | loss: 0.7090012
	speed: 0.3233s/iter; left time: 465.8867s
Epoch: 6 cost time: 102.68300914764404
Epoch: 6 cost time: 101.89084005355835
Epoch: 6, Steps: 343 | Train Loss: 0.4445847 Vali Loss: 0.5184604 Test Loss: 1.3830763
Validation loss decreased (0.519117 --> 0.518460).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6, Steps: 337 | Train Loss: 0.5682028 Vali Loss: 0.6752886 Test Loss: 1.7060479
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 300, epoch: 6 | loss: 0.6806980
	speed: 0.3248s/iter; left time: 435.4905s
Epoch: 6 cost time: 106.6034824848175
	iters: 100, epoch: 7 | loss: 0.4302441
	speed: 0.6587s/iter; left time: 838.4978s
	iters: 100, epoch: 7 | loss: 0.5791576
	speed: 0.6581s/iter; left time: 821.9130s
Epoch: 6, Steps: 328 | Train Loss: 0.6848843 Vali Loss: 0.8333951 Test Loss: 1.9809401
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-05
	iters: 200, epoch: 7 | loss: 0.4440325
	speed: 0.2983s/iter; left time: 349.8624s
	iters: 200, epoch: 7 | loss: 0.6481351
	speed: 0.3011s/iter; left time: 345.9670s
	iters: 100, epoch: 7 | loss: 0.8139203
	speed: 0.6713s/iter; left time: 814.2283s
	iters: 300, epoch: 7 | loss: 0.4677237
	speed: 0.2981s/iter; left time: 319.8556s
	iters: 300, epoch: 7 | loss: 0.5273340
	speed: 0.3010s/iter; left time: 315.7784s
Epoch: 7 cost time: 102.56610703468323
	iters: 200, epoch: 7 | loss: 0.6226159
	speed: 0.3232s/iter; left time: 359.7770s
Epoch: 7 cost time: 101.92633080482483
Epoch: 7, Steps: 343 | Train Loss: 0.4387738 Vali Loss: 0.5173401 Test Loss: 1.3839613
Validation loss decreased (0.518460 --> 0.517340).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7, Steps: 337 | Train Loss: 0.5617499 Vali Loss: 0.6763185 Test Loss: 1.7101735
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 300, epoch: 7 | loss: 0.6819357
	speed: 0.3238s/iter; left time: 328.0031s
Epoch: 7 cost time: 106.40454936027527
	iters: 100, epoch: 8 | loss: 0.4749281
	speed: 0.6583s/iter; left time: 612.1803s
	iters: 100, epoch: 8 | loss: 0.5417278
	speed: 0.6603s/iter; left time: 602.1718s
Epoch: 7, Steps: 328 | Train Loss: 0.6782826 Vali Loss: 0.8348753 Test Loss: 1.9836532
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1288
	iters: 200, epoch: 8 | loss: 0.4533530
	speed: 0.2984s/iter; left time: 247.6400s
	iters: 200, epoch: 8 | loss: 0.4597853
	speed: 0.3051s/iter; left time: 247.7665s
test shape: (1288, 1, 336, 1543) (1288, 1, 336, 1543)
test shape: (1288, 336, 1543) (1288, 336, 1543)
mse:1.9843276739120483, mae:0.6412357091903687
>>>>>>>Overall time: 967 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:Args in experiment:

Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)

Use GPU: cuda:0Use GPU: cuda:0

Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=1543, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5393
train 5249
train 5489
val 477
val 621
val 717
test 1288
test 1432
test 1528
	iters: 100, epoch: 1 | loss: 0.4866584
	speed: 0.1299s/iter; left time: 432.6858s
	iters: 100, epoch: 1 | loss: 0.5632181
	speed: 0.1321s/iter; left time: 432.0260s
	iters: 100, epoch: 1 | loss: 0.6765261
	speed: 0.1355s/iter; left time: 430.8977s
	iters: 200, epoch: 1 | loss: 0.5183553
	speed: 0.1233s/iter; left time: 398.2590s
	iters: 200, epoch: 1 | loss: 0.6189868
	speed: 0.1259s/iter; left time: 399.1064s
	iters: 200, epoch: 1 | loss: 0.8358193
	speed: 0.1317s/iter; left time: 405.8802s
	iters: 300, epoch: 1 | loss: 0.5010336
	speed: 0.1232s/iter; left time: 385.8471s
	iters: 300, epoch: 1 | loss: 0.7183687
	speed: 0.1259s/iter; left time: 386.6069s
	iters: 300, epoch: 1 | loss: 0.7146972
	speed: 0.1315s/iter; left time: 391.9316s
Epoch: 1 cost time: 43.05912709236145
Epoch: 1 cost time: 43.15765714645386
Epoch: 1 cost time: 43.68596792221069
Epoch: 1, Steps: 343 | Train Loss: 0.5064969 Vali Loss: 0.4982250 Test Loss: 1.0985342
Validation loss decreased (inf --> 0.498225).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 337 | Train Loss: 0.6553344 Vali Loss: 0.6725065 Test Loss: 1.4445080
Validation loss decreased (inf --> 0.672506).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 328 | Train Loss: 0.7654284 Vali Loss: 0.8449659 Test Loss: 1.7102847
Validation loss decreased (inf --> 0.844966).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.4775707
	speed: 0.3075s/iter; left time: 918.9214s
	iters: 100, epoch: 2 | loss: 0.5343314
	speed: 0.3145s/iter; left time: 922.6307s
	iters: 100, epoch: 2 | loss: 0.7733196
	speed: 0.3253s/iter; left time: 928.1915s
	iters: 200, epoch: 2 | loss: 0.4695100
	speed: 0.1233s/iter; left time: 356.0373s
	iters: 200, epoch: 2 | loss: 0.6219947
	speed: 0.1261s/iter; left time: 357.4799s
	iters: 200, epoch: 2 | loss: 0.8266695
	speed: 0.1309s/iter; left time: 360.4204s
	iters: 300, epoch: 2 | loss: 0.5475689
	speed: 0.1232s/iter; left time: 343.4591s
	iters: 300, epoch: 2 | loss: 0.7001785
	speed: 0.1262s/iter; left time: 345.0758s
Epoch: 2 cost time: 42.73581647872925
	iters: 300, epoch: 2 | loss: 0.7881514
	speed: 0.1308s/iter; left time: 347.0890s
Epoch: 2 cost time: 42.96931982040405
Epoch: 2 cost time: 43.435243368148804
Epoch: 2, Steps: 343 | Train Loss: 0.4755439 Vali Loss: 0.4866897 Test Loss: 1.0929118
Validation loss decreased (0.498225 --> 0.486690).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 337 | Train Loss: 0.6182657 Vali Loss: 0.6525863 Test Loss: 1.4738711
Validation loss decreased (0.672506 --> 0.652586).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 328 | Train Loss: 0.7350322 Vali Loss: 0.8438550 Test Loss: 1.6886930
Validation loss decreased (0.844966 --> 0.843855).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3415994
	speed: 0.3059s/iter; left time: 809.0614s
	iters: 100, epoch: 3 | loss: 0.4433082
	speed: 0.3169s/iter; left time: 823.0041s
	iters: 100, epoch: 3 | loss: 0.6690473
	speed: 0.3266s/iter; left time: 824.6805s
	iters: 200, epoch: 3 | loss: 0.3663434
	speed: 0.1222s/iter; left time: 311.0144s
	iters: 200, epoch: 3 | loss: 0.5152922
	speed: 0.1260s/iter; left time: 314.5079s
	iters: 200, epoch: 3 | loss: 0.5926882
	speed: 0.1308s/iter; left time: 317.1372s
	iters: 300, epoch: 3 | loss: 0.3823399
	speed: 0.1232s/iter; left time: 301.3416s
	iters: 300, epoch: 3 | loss: 0.5077373
	speed: 0.1262s/iter; left time: 302.3994s
Epoch: 3 cost time: 42.570531129837036
Epoch: 3 cost time: 42.93730330467224
	iters: 300, epoch: 3 | loss: 0.5568466
	speed: 0.1309s/iter; left time: 304.3827s
Epoch: 3 cost time: 43.440640926361084
Epoch: 3, Steps: 343 | Train Loss: 0.4427889 Vali Loss: 0.4563247 Test Loss: 1.0916618
Validation loss decreased (0.486690 --> 0.456325).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 337 | Train Loss: 0.5791739 Vali Loss: 0.6374565 Test Loss: 1.4563483
Validation loss decreased (0.652586 --> 0.637456).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 328 | Train Loss: 0.7029221 Vali Loss: 0.8245820 Test Loss: 1.6935232
Validation loss decreased (0.843855 --> 0.824582).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.4789040
	speed: 0.3092s/iter; left time: 711.7854s
	iters: 100, epoch: 4 | loss: 0.6249920
	speed: 0.3127s/iter; left time: 706.5968s
	iters: 100, epoch: 4 | loss: 0.7689188
	speed: 0.3246s/iter; left time: 713.0621s
	iters: 200, epoch: 4 | loss: 0.3973733
	speed: 0.1234s/iter; left time: 271.6978s
	iters: 200, epoch: 4 | loss: 0.4681215
	speed: 0.1264s/iter; left time: 273.0174s
	iters: 200, epoch: 4 | loss: 0.8210863
	speed: 0.1313s/iter; left time: 275.2923s
	iters: 300, epoch: 4 | loss: 0.3522251
	speed: 0.1233s/iter; left time: 259.1465s
	iters: 300, epoch: 4 | loss: 0.5137814
	speed: 0.1254s/iter; left time: 258.3805s
Epoch: 4 cost time: 42.76597309112549
Epoch: 4 cost time: 42.969823360443115
	iters: 300, epoch: 4 | loss: 0.6261519
	speed: 0.1308s/iter; left time: 261.2366s
Epoch: 4 cost time: 43.471378803253174
Epoch: 4, Steps: 343 | Train Loss: 0.4190957 Vali Loss: 0.4559214 Test Loss: 1.0915668
Validation loss decreased (0.456325 --> 0.455921).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4, Steps: 337 | Train Loss: 0.5517860 Vali Loss: 0.6315195 Test Loss: 1.4362366
Validation loss decreased (0.637456 --> 0.631519).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4, Steps: 328 | Train Loss: 0.6733555 Vali Loss: 0.8164819 Test Loss: 1.7084688
Validation loss decreased (0.824582 --> 0.816482).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3619549
	speed: 0.3099s/iter; left time: 607.1414s
	iters: 100, epoch: 5 | loss: 0.5067210
	speed: 0.3079s/iter; left time: 592.0924s
	iters: 200, epoch: 5 | loss: 0.3963220
	speed: 0.1234s/iter; left time: 229.3499s
	iters: 100, epoch: 5 | loss: 0.6330258
	speed: 0.3204s/iter; left time: 598.8982s
	iters: 200, epoch: 5 | loss: 0.4952556
	speed: 0.1241s/iter; left time: 226.3150s
	iters: 300, epoch: 5 | loss: 0.3163960
	speed: 0.1236s/iter; left time: 217.3603s
	iters: 200, epoch: 5 | loss: 0.6586000
	speed: 0.1303s/iter; left time: 230.5698s
	iters: 300, epoch: 5 | loss: 0.6597994
	speed: 0.1242s/iter; left time: 214.0418s
Epoch: 5 cost time: 42.79302382469177
Epoch: 5 cost time: 42.46015501022339
	iters: 300, epoch: 5 | loss: 0.7458760
	speed: 0.1308s/iter; left time: 218.2710s
Epoch: 5, Steps: 343 | Train Loss: 0.4034189 Vali Loss: 0.4509249 Test Loss: 1.1032498
Validation loss decreased (0.455921 --> 0.450925).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 43.35940170288086
Epoch: 5, Steps: 337 | Train Loss: 0.5307780 Vali Loss: 0.6239345 Test Loss: 1.4559461
Validation loss decreased (0.631519 --> 0.623935).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.4027165
	speed: 0.3109s/iter; left time: 502.4163s
Epoch: 5, Steps: 328 | Train Loss: 0.6498067 Vali Loss: 0.8192911 Test Loss: 1.6821545
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5101765
	speed: 0.3061s/iter; left time: 485.4185s
	iters: 200, epoch: 6 | loss: 0.3565862
	speed: 0.1234s/iter; left time: 187.0582s
	iters: 100, epoch: 6 | loss: 0.5283992
	speed: 0.3176s/iter; left time: 489.3941s
	iters: 200, epoch: 6 | loss: 0.4387977
	speed: 0.1243s/iter; left time: 184.6635s
	iters: 300, epoch: 6 | loss: 0.3640760
	speed: 0.1233s/iter; left time: 174.6150s
	iters: 200, epoch: 6 | loss: 0.6650070
	speed: 0.1303s/iter; left time: 187.7850s
	iters: 300, epoch: 6 | loss: 0.4626022
	speed: 0.1242s/iter; left time: 172.2075s
Epoch: 6 cost time: 42.82055425643921
Epoch: 6 cost time: 42.48640060424805
	iters: 300, epoch: 6 | loss: 0.6228338
	speed: 0.1305s/iter; left time: 174.9348s
Epoch: 6, Steps: 343 | Train Loss: 0.3923751 Vali Loss: 0.4473893 Test Loss: 1.1007032
Validation loss decreased (0.450925 --> 0.447389).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 43.276232957839966
Epoch: 6, Steps: 337 | Train Loss: 0.5176268 Vali Loss: 0.6261631 Test Loss: 1.4552476
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3566003
	speed: 0.3123s/iter; left time: 397.5255s
Epoch: 6, Steps: 328 | Train Loss: 0.6318223 Vali Loss: 0.8159571 Test Loss: 1.6751176
Validation loss decreased (0.816482 --> 0.815957).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5115809
	speed: 0.3156s/iter; left time: 394.1688s
	iters: 200, epoch: 7 | loss: 0.3815658
	speed: 0.1237s/iter; left time: 145.1188s
	iters: 200, epoch: 7 | loss: 0.6227307
	speed: 0.1260s/iter; left time: 144.7730s
	iters: 100, epoch: 7 | loss: 0.7827725
	speed: 0.3218s/iter; left time: 390.2953s
	iters: 300, epoch: 7 | loss: 0.4346098
	speed: 0.1236s/iter; left time: 132.6363s
	iters: 300, epoch: 7 | loss: 0.4570871
	speed: 0.1248s/iter; left time: 130.8839s
Epoch: 7 cost time: 42.890989542007446
	iters: 200, epoch: 7 | loss: 0.5454687
	speed: 0.1306s/iter; left time: 145.3465s
Epoch: 7 cost time: 42.840542793273926
Epoch: 7, Steps: 343 | Train Loss: 0.3858218 Vali Loss: 0.4471726 Test Loss: 1.0996062
Validation loss decreased (0.447389 --> 0.447173).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 300, epoch: 7 | loss: 0.6177573
	speed: 0.1308s/iter; left time: 132.5100s
Epoch: 7 cost time: 43.436378717422485
Epoch: 7, Steps: 337 | Train Loss: 0.5098217 Vali Loss: 0.6266935 Test Loss: 1.4471835
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.4047844
	speed: 0.3096s/iter; left time: 287.9442s
	iters: 100, epoch: 8 | loss: 0.4797789
	speed: 0.3140s/iter; left time: 286.3590s
Epoch: 7, Steps: 328 | Train Loss: 0.6221964 Vali Loss: 0.8179495 Test Loss: 1.6741339
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-05
	iters: 200, epoch: 8 | loss: 0.4233848
	speed: 0.1233s/iter; left time: 102.3351s
	iters: 200, epoch: 8 | loss: 0.4024639
	speed: 0.1267s/iter; left time: 102.9138s
	iters: 100, epoch: 8 | loss: 0.7106299
	speed: 0.3201s/iter; left time: 283.2767s
	iters: 300, epoch: 8 | loss: 0.4083251
	speed: 0.1232s/iter; left time: 89.9393s
Epoch: 8 cost time: 42.743441104888916
	iters: 300, epoch: 8 | loss: 0.5436891
	speed: 0.1267s/iter; left time: 90.2037s
	iters: 200, epoch: 8 | loss: 0.6035572
	speed: 0.1303s/iter; left time: 102.3169s
Epoch: 8 cost time: 43.330633878707886
Epoch: 8, Steps: 343 | Train Loss: 0.3824032 Vali Loss: 0.4485089 Test Loss: 1.1008713
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-06
	iters: 300, epoch: 8 | loss: 0.5642787
	speed: 0.1307s/iter; left time: 89.5570s
Epoch: 8, Steps: 337 | Train Loss: 0.5057699 Vali Loss: 0.6267042 Test Loss: 1.4484938
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Epoch: 8 cost time: 43.303298234939575
test 1432
	iters: 100, epoch: 9 | loss: 0.3740715
	speed: 0.3071s/iter; left time: 180.2570s
test shape: (1432, 1, 192, 867) (1432, 1, 192, 867)
test shape: (1432, 192, 867) (1432, 192, 867)
mse:1.4559440612792969, mae:0.6218872666358948
>>>>>>>Overall time: 471 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Epoch: 8, Steps: 328 | Train Loss: 0.6170254 Vali Loss: 0.8171185 Test Loss: 1.6753366
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-06
	iters: 200, epoch: 9 | loss: 0.3372084
	speed: 0.1234s/iter; left time: 60.1102s
	iters: 100, epoch: 9 | loss: 0.6239991
	speed: 0.3211s/iter; left time: 178.8754s
	iters: 300, epoch: 9 | loss: 0.4057578
	speed: 0.1232s/iter; left time: 47.6941s
Epoch: 9 cost time: 42.76587677001953
	iters: 200, epoch: 9 | loss: 0.5497758
	speed: 0.1320s/iter; left time: 60.3360s
Epoch: 9, Steps: 343 | Train Loss: 0.3805849 Vali Loss: 0.4498097 Test Loss: 1.1021146
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-06
	iters: 300, epoch: 9 | loss: 0.5974414
	speed: 0.1316s/iter; left time: 46.9963s
Epoch: 9 cost time: 43.80399966239929
	iters: 100, epoch: 10 | loss: 0.3865105
	speed: 0.3031s/iter; left time: 73.9626s
	iters: 200, epoch: 10 | loss: 0.4064159
	speed: 0.1235s/iter; left time: 17.7783s
Epoch: 9, Steps: 328 | Train Loss: 0.6145331 Vali Loss: 0.8201771 Test Loss: 1.6780736
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1288
	iters: 300, epoch: 10 | loss: 0.4499948
	speed: 0.1232s/iter; left time: 5.4208s
test shape: (1288, 1, 336, 867) (1288, 1, 336, 867)
test shape: (1288, 336, 867) (1288, 336, 867)
Epoch: 10 cost time: 42.752166509628296
mse:1.6751179695129395, mae:0.6779167652130127
>>>>>>>Overall time: 548 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:Args in experiment:Args in experiment:


Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=867, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=867, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=867, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=867, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=867, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=867, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=867, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=867, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=867, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)

Use GPU: cuda:0
Use GPU: cuda:0Use GPU: cuda:0

>>>>>>>start training : long_term_forecast_pems12_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5489
train 5393
train 5249
val 717
val 621
val 477
test 1528
test 1432
test 1288
	iters: 100, epoch: 1 | loss: 0.4866584
	speed: 0.1286s/iter; left time: 428.2865s
	iters: 100, epoch: 1 | loss: 0.5632181
	speed: 0.1294s/iter; left time: 423.2096s
	iters: 100, epoch: 1 | loss: 0.6765261
	speed: 0.1357s/iter; left time: 431.7185s
	iters: 200, epoch: 1 | loss: 0.5183550
	speed: 0.1229s/iter; left time: 397.0361s
	iters: 200, epoch: 1 | loss: 0.6189905
	speed: 0.1262s/iter; left time: 400.3382s
	iters: 200, epoch: 1 | loss: 0.8341087
	speed: 0.1308s/iter; left time: 403.0392s
	iters: 300, epoch: 1 | loss: 0.5039074
	speed: 0.1230s/iter; left time: 385.2145s
	iters: 300, epoch: 1 | loss: 0.7086643
	speed: 0.1259s/iter; left time: 386.7780s
	iters: 300, epoch: 1 | loss: 0.7312112
	speed: 0.1309s/iter; left time: 390.2102s
Epoch: 1 cost time: 42.8285608291626
Epoch: 1 cost time: 42.90686559677124
Epoch: 1 cost time: 43.501628398895264
Epoch: 1, Steps: 343 | Train Loss: 0.5063931 Vali Loss: 0.4996672 Test Loss: 1.0960413
Validation loss decreased (inf --> 0.499667).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 337 | Train Loss: 0.6554066 Vali Loss: 0.6697723 Test Loss: 1.4536798
Validation loss decreased (inf --> 0.669772).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 328 | Train Loss: 0.7655297 Vali Loss: 0.8419529 Test Loss: 1.7165318
Validation loss decreased (inf --> 0.841953).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.4816599
	speed: 0.3030s/iter; left time: 905.4181s
	iters: 100, epoch: 2 | loss: 0.5310470
	speed: 0.3073s/iter; left time: 901.7040s
	iters: 100, epoch: 2 | loss: 0.7761230
	speed: 0.3185s/iter; left time: 908.8095s
	iters: 200, epoch: 2 | loss: 0.4668040
	speed: 0.1234s/iter; left time: 356.4411s
	iters: 200, epoch: 2 | loss: 0.6022994
	speed: 0.1256s/iter; left time: 355.9384s
	iters: 200, epoch: 2 | loss: 0.8260930
	speed: 0.1288s/iter; left time: 354.5051s
	iters: 300, epoch: 2 | loss: 0.5564353
	speed: 0.1235s/iter; left time: 344.1900s
	iters: 300, epoch: 2 | loss: 0.7015514
	speed: 0.1257s/iter; left time: 343.5909s
	iters: 300, epoch: 2 | loss: 0.8046085
	speed: 0.1289s/iter; left time: 341.8643s
Epoch: 2 cost time: 42.7591335773468
Epoch: 2 cost time: 42.684650182724
Epoch: 2 cost time: 42.722081899642944
Epoch: 2, Steps: 343 | Train Loss: 0.4768249 Vali Loss: 0.4874378 Test Loss: 1.1068280
Validation loss decreased (0.499667 --> 0.487438).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 337 | Train Loss: 0.6192649 Vali Loss: 0.6576853 Test Loss: 1.4487419
Validation loss decreased (0.669772 --> 0.657685).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2, Steps: 328 | Train Loss: 0.7339098 Vali Loss: 0.8414821 Test Loss: 1.6692913
Validation loss decreased (0.841953 --> 0.841482).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3475061
	speed: 0.3013s/iter; left time: 796.9067s
	iters: 100, epoch: 3 | loss: 0.4538203
	speed: 0.3060s/iter; left time: 794.7226s
	iters: 100, epoch: 3 | loss: 0.6710299
	speed: 0.3084s/iter; left time: 778.6417s
	iters: 200, epoch: 3 | loss: 0.3710592
	speed: 0.1229s/iter; left time: 312.7240s
	iters: 200, epoch: 3 | loss: 0.5158833
	speed: 0.1256s/iter; left time: 313.7061s
	iters: 200, epoch: 3 | loss: 0.5874478
	speed: 0.1289s/iter; left time: 312.4985s
	iters: 300, epoch: 3 | loss: 0.3909040
	speed: 0.1229s/iter; left time: 300.5104s
	iters: 300, epoch: 3 | loss: 0.5035865
	speed: 0.1257s/iter; left time: 301.1856s
Epoch: 3 cost time: 42.58338904380798
	iters: 300, epoch: 3 | loss: 0.5577583
	speed: 0.1286s/iter; left time: 299.0707s
Epoch: 3 cost time: 42.723567485809326
Epoch: 3 cost time: 42.876253604888916
Epoch: 3, Steps: 343 | Train Loss: 0.4449450 Vali Loss: 0.4578741 Test Loss: 1.0931121
Validation loss decreased (0.487438 --> 0.457874).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 337 | Train Loss: 0.5797897 Vali Loss: 0.6346485 Test Loss: 1.4725850
Validation loss decreased (0.657685 --> 0.634649).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 328 | Train Loss: 0.7007837 Vali Loss: 0.8260335 Test Loss: 1.6886442
Validation loss decreased (0.841482 --> 0.826033).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.4798484
	speed: 0.3028s/iter; left time: 696.9602s
	iters: 100, epoch: 4 | loss: 0.6223603
	speed: 0.3109s/iter; left time: 702.7265s
	iters: 100, epoch: 4 | loss: 0.7573192
	speed: 0.3179s/iter; left time: 698.4300s
	iters: 200, epoch: 4 | loss: 0.4008095
	speed: 0.1230s/iter; left time: 270.7840s
	iters: 200, epoch: 4 | loss: 0.4659622
	speed: 0.1254s/iter; left time: 270.8359s
	iters: 200, epoch: 4 | loss: 0.8249850
	speed: 0.1285s/iter; left time: 269.4658s
	iters: 300, epoch: 4 | loss: 0.3479569
	speed: 0.1230s/iter; left time: 258.5023s
	iters: 300, epoch: 4 | loss: 0.5144507
	speed: 0.1255s/iter; left time: 258.5004s
Epoch: 4 cost time: 42.586451292037964
Epoch: 4 cost time: 42.65437388420105
	iters: 300, epoch: 4 | loss: 0.6147331
	speed: 0.1287s/iter; left time: 256.9728s
Epoch: 4 cost time: 42.59995698928833
Epoch: 4, Steps: 343 | Train Loss: 0.4205717 Vali Loss: 0.4578867 Test Loss: 1.0802001
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
Epoch: 4, Steps: 337 | Train Loss: 0.5523240 Vali Loss: 0.6295791 Test Loss: 1.4543858
Validation loss decreased (0.634649 --> 0.629579).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4, Steps: 328 | Train Loss: 0.6715201 Vali Loss: 0.8221601 Test Loss: 1.7084813
Validation loss decreased (0.826033 --> 0.822160).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3624092
	speed: 0.3004s/iter; left time: 588.5384s
	iters: 100, epoch: 5 | loss: 0.5097392
	speed: 0.3042s/iter; left time: 584.9825s
	iters: 100, epoch: 5 | loss: 0.6321014
	speed: 0.3124s/iter; left time: 583.8920s
	iters: 200, epoch: 5 | loss: 0.3929906
	speed: 0.1229s/iter; left time: 228.3958s
	iters: 200, epoch: 5 | loss: 0.4986943
	speed: 0.1255s/iter; left time: 228.8200s
	iters: 200, epoch: 5 | loss: 0.6573529
	speed: 0.1281s/iter; left time: 226.5395s
	iters: 300, epoch: 5 | loss: 0.3168103
	speed: 0.1229s/iter; left time: 216.2095s
	iters: 300, epoch: 5 | loss: 0.6478130
	speed: 0.1255s/iter; left time: 216.3144s
Epoch: 5 cost time: 42.55740547180176
Epoch: 5 cost time: 42.65424680709839
	iters: 300, epoch: 5 | loss: 0.7359086
	speed: 0.1283s/iter; left time: 214.1533s
Epoch: 5 cost time: 42.48834753036499
Epoch: 5, Steps: 343 | Train Loss: 0.4045795 Vali Loss: 0.4509124 Test Loss: 1.0834088
Validation loss decreased (0.457874 --> 0.450912).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5, Steps: 337 | Train Loss: 0.5314630 Vali Loss: 0.6248591 Test Loss: 1.4615721
Validation loss decreased (0.629579 --> 0.624859).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.4007009
	speed: 0.3010s/iter; left time: 486.4046s
Epoch: 5, Steps: 328 | Train Loss: 0.6472392 Vali Loss: 0.8275934 Test Loss: 1.6871967
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5122398
	speed: 0.3100s/iter; left time: 491.6700s
	iters: 200, epoch: 6 | loss: 0.3547946
	speed: 0.1231s/iter; left time: 186.6256s
	iters: 100, epoch: 6 | loss: 0.5300925
	speed: 0.3182s/iter; left time: 490.3370s
	iters: 200, epoch: 6 | loss: 0.4415079
	speed: 0.1256s/iter; left time: 186.6905s
	iters: 300, epoch: 6 | loss: 0.3681192
	speed: 0.1230s/iter; left time: 174.2030s
	iters: 200, epoch: 6 | loss: 0.6625503
	speed: 0.1284s/iter; left time: 184.9987s
Epoch: 6 cost time: 42.61979103088379
	iters: 300, epoch: 6 | loss: 0.4591020
	speed: 0.1254s/iter; left time: 173.8318s
Epoch: 6 cost time: 42.66522264480591
	iters: 300, epoch: 6 | loss: 0.6191479
	speed: 0.1286s/iter; left time: 172.4012s
Epoch: 6, Steps: 343 | Train Loss: 0.3936406 Vali Loss: 0.4503081 Test Loss: 1.0841345
Validation loss decreased (0.450912 --> 0.450308).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 42.61997413635254
Epoch: 6, Steps: 337 | Train Loss: 0.5181988 Vali Loss: 0.6256428 Test Loss: 1.4569044
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3567179
	speed: 0.3003s/iter; left time: 382.2710s
Epoch: 6, Steps: 328 | Train Loss: 0.6300932 Vali Loss: 0.8239191 Test Loss: 1.6805613
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5097377
	speed: 0.3057s/iter; left time: 381.8041s
	iters: 200, epoch: 7 | loss: 0.3829935
	speed: 0.1230s/iter; left time: 144.2672s
	iters: 100, epoch: 7 | loss: 0.7825481
	speed: 0.3142s/iter; left time: 381.1610s
	iters: 200, epoch: 7 | loss: 0.6219248
	speed: 0.1255s/iter; left time: 144.2366s
	iters: 300, epoch: 7 | loss: 0.4326327
	speed: 0.1230s/iter; left time: 131.9778s
	iters: 200, epoch: 7 | loss: 0.5410673
	speed: 0.1287s/iter; left time: 143.2796s
Epoch: 7 cost time: 42.57547974586487
	iters: 300, epoch: 7 | loss: 0.4534793
	speed: 0.1255s/iter; left time: 131.6332s
Epoch: 7 cost time: 42.725058794021606
	iters: 300, epoch: 7 | loss: 0.6191790
	speed: 0.1288s/iter; left time: 130.4552s
Epoch: 7, Steps: 343 | Train Loss: 0.3869142 Vali Loss: 0.4514254 Test Loss: 1.0845174
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 42.76459360122681
Epoch: 7, Steps: 337 | Train Loss: 0.5103155 Vali Loss: 0.6266738 Test Loss: 1.4590237
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.4048485
	speed: 0.2993s/iter; left time: 278.3037s
Epoch: 7, Steps: 328 | Train Loss: 0.6206959 Vali Loss: 0.8269061 Test Loss: 1.6837900
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1288
	iters: 100, epoch: 8 | loss: 0.4785368
	speed: 0.3008s/iter; left time: 274.3441s
	iters: 200, epoch: 8 | loss: 0.4251535
	speed: 0.1230s/iter; left time: 102.1059s
test shape: (1288, 1, 336, 867) (1288, 1, 336, 867)
test shape: (1288, 336, 867) (1288, 336, 867)
	iters: 200, epoch: 8 | loss: 0.4024983
	speed: 0.1257s/iter; left time: 102.0619s
mse:1.7084845304489136, mae:0.6881837844848633
>>>>>>>Overall time: 425 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
