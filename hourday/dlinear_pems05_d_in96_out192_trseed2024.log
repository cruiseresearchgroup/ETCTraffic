Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=103, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems05_d.csv', dec_in=103, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=103, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems05_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems05_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2790
val 250
test 688
Epoch: 1 cost time: 1.2672233581542969
Epoch: 1, Steps: 87 | Train Loss: 0.9084607 Vali Loss: 0.7999373 Test Loss: 0.7103703
Validation loss decreased (inf --> 0.799937).  Saving model ...
Epoch: 2 cost time: 1.0469238758087158
Epoch: 2, Steps: 87 | Train Loss: 0.8527868 Vali Loss: 0.8004146 Test Loss: 0.7015960
EarlyStopping counter: 1 out of 5
Epoch: 3 cost time: 1.0943448543548584
Epoch: 3, Steps: 87 | Train Loss: 0.8455126 Vali Loss: 0.7989259 Test Loss: 0.7012471
Validation loss decreased (0.799937 --> 0.798926).  Saving model ...
Epoch: 4 cost time: 1.067704439163208
Epoch: 4, Steps: 87 | Train Loss: 0.8429983 Vali Loss: 0.7835292 Test Loss: 0.6980407
Validation loss decreased (0.798926 --> 0.783529).  Saving model ...
Epoch: 5 cost time: 1.0928077697753906
Epoch: 5, Steps: 87 | Train Loss: 0.8411085 Vali Loss: 0.7885900 Test Loss: 0.6986079
EarlyStopping counter: 1 out of 5
Epoch: 6 cost time: 1.0927913188934326
Epoch: 6, Steps: 87 | Train Loss: 0.8411280 Vali Loss: 0.7830825 Test Loss: 0.6987363
Validation loss decreased (0.783529 --> 0.783082).  Saving model ...
Epoch: 7 cost time: 1.0610835552215576
Epoch: 7, Steps: 87 | Train Loss: 0.8411138 Vali Loss: 0.7997674 Test Loss: 0.6987818
EarlyStopping counter: 1 out of 5
Epoch: 8 cost time: 1.0433335304260254
Epoch: 8, Steps: 87 | Train Loss: 0.8404433 Vali Loss: 0.7809270 Test Loss: 0.6983917
Validation loss decreased (0.783082 --> 0.780927).  Saving model ...
Epoch: 9 cost time: 1.10609769821167
Epoch: 9, Steps: 87 | Train Loss: 0.8401931 Vali Loss: 0.7941512 Test Loss: 0.6991767
EarlyStopping counter: 1 out of 5
Epoch: 10 cost time: 1.1051008701324463
Epoch: 10, Steps: 87 | Train Loss: 0.8405484 Vali Loss: 0.7856029 Test Loss: 0.6983699
EarlyStopping counter: 2 out of 5
Epoch: 11 cost time: 1.064363956451416
Epoch: 11, Steps: 87 | Train Loss: 0.8410342 Vali Loss: 0.7935104 Test Loss: 0.6999019
EarlyStopping counter: 3 out of 5
Epoch: 12 cost time: 1.0543708801269531
Epoch: 12, Steps: 87 | Train Loss: 0.8406577 Vali Loss: 0.7901667 Test Loss: 0.6984528
EarlyStopping counter: 4 out of 5
Epoch: 13 cost time: 1.0685434341430664
Epoch: 13, Steps: 87 | Train Loss: 0.8396642 Vali Loss: 0.7974327 Test Loss: 0.7013466
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems05_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 688
test shape: (688, 1, 192, 103) (688, 1, 192, 103)
test shape: (688, 192, 103) (688, 192, 103)
mse:0.6983911395072937, mae:0.5353125929832458
>>>>>>>Overall time: 66 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
