Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5383
val 703
test 1497
	iters: 100, epoch: 1 | loss: 0.5363705
	speed: 0.1179s/iter; left time: 3951.1668s
Epoch: 1 cost time: 19.616880178451538
Epoch: 1, Steps: 168 | Train Loss: 0.5550317 Vali Loss: 0.3680492 Test Loss: 0.6073188
Validation loss decreased (inf --> 0.368049).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.3457837
	speed: 0.3983s/iter; left time: 13274.9704s
Epoch: 2 cost time: 20.959941625595093
Epoch: 2, Steps: 168 | Train Loss: 0.4806282 Vali Loss: 0.3861862 Test Loss: 0.6556498
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 3 | loss: 0.4707981
	speed: 0.4031s/iter; left time: 13369.3717s
Epoch: 3 cost time: 20.89072871208191
Epoch: 3, Steps: 168 | Train Loss: 0.4180074 Vali Loss: 0.3906487 Test Loss: 0.6371285
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 4 | loss: 0.3244170
	speed: 0.3936s/iter; left time: 12988.2282s
Epoch: 4 cost time: 19.503653049468994
Epoch: 4, Steps: 168 | Train Loss: 0.3447154 Vali Loss: 0.3990551 Test Loss: 0.6596636
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 5 | loss: 0.2600082
	speed: 0.3888s/iter; left time: 12763.1069s
Epoch: 5 cost time: 19.4319748878479
Epoch: 5, Steps: 168 | Train Loss: 0.2903354 Vali Loss: 0.4060068 Test Loss: 0.6775023
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 6 | loss: 0.3632042
	speed: 0.3898s/iter; left time: 12730.5311s
Epoch: 6 cost time: 19.6246075630188
Epoch: 6, Steps: 168 | Train Loss: 0.3775272 Vali Loss: 0.4191357 Test Loss: 0.6889986
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1497
Traceback (most recent call last):
  File "run.py", line 161, in <module>
    exp.test(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 286, in test
    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 89, in visual
    plt.savefig(name, bbox_inches='tight')
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/pyplot.py", line 996, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/figure.py", line 3328, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2362, in print_figure
    result = print_method(
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2228, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 2823, in print_pdf
    file.close()
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/matplotlib/backends/backend_pdf.py", line 890, in close
    self.fh.close()
OSError: [Errno 122] Disk quota exceeded
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5383
val 703
test 1497
	iters: 100, epoch: 1 | loss: 0.5360178
	speed: 0.1260s/iter; left time: 4222.2853s
Epoch: 1 cost time: 20.765145301818848
Epoch: 1, Steps: 168 | Train Loss: 0.5553783 Vali Loss: 0.3717783 Test Loss: 0.6439901
Validation loss decreased (inf --> 0.371778).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.3486502
	speed: 0.4068s/iter; left time: 13559.6359s
Epoch: 2 cost time: 20.445074319839478
Epoch: 2, Steps: 168 | Train Loss: 0.4800339 Vali Loss: 0.3745628 Test Loss: 0.6422299
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 3 | loss: 0.4717801
	speed: 0.4046s/iter; left time: 13417.2357s
Epoch: 3 cost time: 20.562408685684204
Epoch: 3, Steps: 168 | Train Loss: 0.4174455 Vali Loss: 0.3914420 Test Loss: 0.6521540
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 4 | loss: 0.3281979
	speed: 0.4068s/iter; left time: 13423.6675s
Epoch: 4 cost time: 20.75234365463257
Epoch: 4, Steps: 168 | Train Loss: 0.3972322 Vali Loss: 0.3879986 Test Loss: 0.6059440
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 5 | loss: 0.3123048
	speed: 0.4042s/iter; left time: 13268.2020s
Epoch: 5 cost time: 20.54810619354248
Epoch: 5, Steps: 168 | Train Loss: 0.3983053 Vali Loss: 0.4105978 Test Loss: 0.6925539
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 6 | loss: 0.3082660
	speed: 0.4054s/iter; left time: 13240.5353s
Epoch: 6 cost time: 20.252965927124023
Epoch: 6, Steps: 168 | Train Loss: 0.3046735 Vali Loss: 0.4048082 Test Loss: 0.6683381
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1497
test shape: (1497, 1, 96, 822) (1497, 1, 96, 822)
test shape: (1497, 96, 822) (1497, 96, 822)
mse:0.6439885497093201, mae:0.5059775710105896
>>>>>>>Overall time: 269 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
