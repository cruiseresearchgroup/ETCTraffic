Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1613, checkpoints='./checkpoints/', d_conv=4, d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems07_d.csv', dec_in=1613, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=1613, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems07_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems07_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.7832448
	speed: 0.2115s/iter; left time: 6958.0172s
Epoch: 1 cost time: 34.12446999549866
Epoch: 1, Steps: 165 | Train Loss: 0.8044475 Vali Loss: 1.2392945 Test Loss: 1.9201207
Validation loss decreased (inf --> 1.239295).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.6700202
	speed: 0.5872s/iter; left time: 19223.0544s
Epoch: 2 cost time: 33.38499402999878
Epoch: 2, Steps: 165 | Train Loss: 0.6946735 Vali Loss: 1.2396845 Test Loss: 1.9441324
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 3 | loss: 0.6787116
	speed: 0.5857s/iter; left time: 19075.2431s
Epoch: 3 cost time: 33.35782980918884
Epoch: 3, Steps: 165 | Train Loss: 0.6502496 Vali Loss: 1.2540221 Test Loss: 1.9501270
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 4 | loss: 0.6193754
	speed: 0.5841s/iter; left time: 18929.2507s
Epoch: 4 cost time: 32.833786487579346
Epoch: 4, Steps: 165 | Train Loss: 0.6145371 Vali Loss: 1.2789310 Test Loss: 1.9672663
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 5 | loss: 0.7297661
	speed: 0.5823s/iter; left time: 18775.2258s
Epoch: 5 cost time: 32.99725103378296
Epoch: 5, Steps: 165 | Train Loss: 0.6726877 Vali Loss: 1.2167445 Test Loss: 1.9027278
Validation loss decreased (1.239295 --> 1.216745).  Saving model ...
	iters: 100, epoch: 6 | loss: 0.7211823
	speed: 0.5856s/iter; left time: 18784.1747s
Epoch: 6 cost time: 33.366692543029785
Epoch: 6, Steps: 165 | Train Loss: 0.6875885 Vali Loss: 1.2242684 Test Loss: 1.9051794
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 7 | loss: 0.6798812
	speed: 0.5853s/iter; left time: 18676.7429s
Epoch: 7 cost time: 32.96191048622131
Epoch: 7, Steps: 165 | Train Loss: 0.6640020 Vali Loss: 1.2434582 Test Loss: 1.9038932
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 8 | loss: 0.6554563
	speed: 0.5823s/iter; left time: 18486.1956s
Epoch: 8 cost time: 33.04022669792175
Epoch: 8, Steps: 165 | Train Loss: 0.6398658 Vali Loss: 1.2401432 Test Loss: 1.9055107
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 9 | loss: 0.6124780
	speed: 0.5865s/iter; left time: 18521.5289s
Epoch: 9 cost time: 33.33141875267029
Epoch: 9, Steps: 165 | Train Loss: 0.6121554 Vali Loss: 1.2297491 Test Loss: 1.9101111
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 10 | loss: 0.5673226
	speed: 0.5860s/iter; left time: 18409.9739s
Epoch: 10 cost time: 33.41374969482422
Epoch: 10, Steps: 165 | Train Loss: 0.5831978 Vali Loss: 1.2674775 Test Loss: 1.9097921
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems07_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
test shape: (1401, 1, 192, 1613) (1401, 1, 192, 1613)
test shape: (1401, 192, 1613) (1401, 192, 1613)
mse:1.902725338935852, mae:0.8036066889762878
>>>>>>>Overall time: 621 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
