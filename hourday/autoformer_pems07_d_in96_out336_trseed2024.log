Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1613, checkpoints='./checkpoints/', d_conv=4, d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems07_d.csv', dec_in=1613, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=1613, expand=2, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems07_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems07_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.8888553
	speed: 0.2809s/iter; left time: 8961.0291s
Epoch: 1 cost time: 44.73720932006836
Epoch: 1, Steps: 160 | Train Loss: 0.8934402 Vali Loss: 1.5919806 Test Loss: 2.1838820
Validation loss decreased (inf --> 1.591981).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.8211915
	speed: 0.7151s/iter; left time: 22698.0935s
Epoch: 2 cost time: 44.68732213973999
Epoch: 2, Steps: 160 | Train Loss: 0.8284950 Vali Loss: 1.5771674 Test Loss: 2.1709054
Validation loss decreased (1.591981 --> 1.577167).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.8373700
	speed: 0.7138s/iter; left time: 22544.0161s
Epoch: 3 cost time: 45.12680959701538
Epoch: 3, Steps: 160 | Train Loss: 0.8087406 Vali Loss: 1.5872490 Test Loss: 2.1696820
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.7563912
	speed: 0.7160s/iter; left time: 22495.9130s
Epoch: 4 cost time: 44.50078511238098
Epoch: 4, Steps: 160 | Train Loss: 0.8139083 Vali Loss: 1.6042122 Test Loss: 2.1819141
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.7901186
	speed: 0.7217s/iter; left time: 22560.2161s
Epoch: 5 cost time: 45.14266610145569
Epoch: 5, Steps: 160 | Train Loss: 0.8075189 Vali Loss: 1.6002547 Test Loss: 2.1752861
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.7737898
	speed: 0.7130s/iter; left time: 22175.4388s
Epoch: 6 cost time: 44.06249928474426
Epoch: 6, Steps: 160 | Train Loss: 0.7856619 Vali Loss: 1.6319221 Test Loss: 2.1851850
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.7942622
	speed: 0.7116s/iter; left time: 22018.6284s
Epoch: 7 cost time: 44.86891794204712
Epoch: 7, Steps: 160 | Train Loss: 0.7626359 Vali Loss: 1.6280538 Test Loss: 2.1804359
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems07_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 1613) (1257, 1, 336, 1613)
test shape: (1257, 336, 1613) (1257, 336, 1613)
mse:2.170919895172119, mae:0.8840540647506714
>>>>>>>Overall time: 539 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
