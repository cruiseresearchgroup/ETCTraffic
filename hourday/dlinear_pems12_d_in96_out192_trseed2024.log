Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1543, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5393
val 621
test 1432
	iters: 100, epoch: 1 | loss: 0.6551186
	speed: 0.0786s/iter; left time: 2632.5365s
Epoch: 1 cost time: 12.89246416091919
Epoch: 1, Steps: 168 | Train Loss: 0.6922657 Vali Loss: 0.7033865 Test Loss: 1.6865096
Validation loss decreased (inf --> 0.703386).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.6736218
	speed: 0.2504s/iter; left time: 8346.5856s
Epoch: 2 cost time: 12.611708164215088
Epoch: 2, Steps: 168 | Train Loss: 0.6621059 Vali Loss: 0.6988531 Test Loss: 1.6850368
Validation loss decreased (0.703386 --> 0.698853).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.6230231
	speed: 0.2500s/iter; left time: 8291.0768s
Epoch: 3 cost time: 12.549189805984497
Epoch: 3, Steps: 168 | Train Loss: 0.6602683 Vali Loss: 0.6995916 Test Loss: 1.6857044
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.6801155
	speed: 0.2532s/iter; left time: 8355.2739s
Epoch: 4 cost time: 12.518628597259521
Epoch: 4, Steps: 168 | Train Loss: 0.6607920 Vali Loss: 0.6995493 Test Loss: 1.6858498
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.6824421
	speed: 0.2497s/iter; left time: 8196.2034s
Epoch: 5 cost time: 12.521823406219482
Epoch: 5, Steps: 168 | Train Loss: 0.6604533 Vali Loss: 0.7005985 Test Loss: 1.6863561
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.5798776
	speed: 0.2507s/iter; left time: 8189.7320s
Epoch: 6 cost time: 12.650014162063599
Epoch: 6, Steps: 168 | Train Loss: 0.6607012 Vali Loss: 0.6995109 Test Loss: 1.6853220
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.6570882
	speed: 0.2499s/iter; left time: 8119.5975s
Epoch: 7 cost time: 12.542312145233154
Epoch: 7, Steps: 168 | Train Loss: 0.6609581 Vali Loss: 0.7000160 Test Loss: 1.6869568
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1432
test shape: (1432, 1, 192, 1543) (1432, 1, 192, 1543)
test shape: (1432, 192, 1543) (1432, 192, 1543)
mse:1.685027003288269, mae:0.5778661966323853
>>>>>>>Overall time: 211 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1543, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=1543, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=1543, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5393
val 621
test 1432
	iters: 100, epoch: 1 | loss: 0.6177838
	speed: 0.0385s/iter; left time: 1290.9472s
Epoch: 1 cost time: 6.065800428390503
Epoch: 1, Steps: 168 | Train Loss: 0.6797039 Vali Loss: 0.6694846 Test Loss: 1.4122880
Validation loss decreased (inf --> 0.669485).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.6438959
	speed: 0.1279s/iter; left time: 4263.5199s
Epoch: 2 cost time: 5.843327283859253
Epoch: 2, Steps: 168 | Train Loss: 0.6362966 Vali Loss: 0.6615345 Test Loss: 1.4066099
Validation loss decreased (0.669485 --> 0.661534).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.5689481
	speed: 0.1301s/iter; left time: 4314.4079s
Epoch: 3 cost time: 5.866617679595947
Epoch: 3, Steps: 168 | Train Loss: 0.6330533 Vali Loss: 0.6614845 Test Loss: 1.4043895
Validation loss decreased (0.661534 --> 0.661484).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.6553214
	speed: 0.1300s/iter; left time: 4291.1646s
Epoch: 4 cost time: 5.874704360961914
Epoch: 4, Steps: 168 | Train Loss: 0.6335807 Vali Loss: 0.6612512 Test Loss: 1.4041456
Validation loss decreased (0.661484 --> 0.661251).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.6412400
	speed: 0.1284s/iter; left time: 4215.6251s
Epoch: 5 cost time: 5.836113691329956
Epoch: 5, Steps: 168 | Train Loss: 0.6329767 Vali Loss: 0.6631392 Test Loss: 1.4044172
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 6 | loss: 0.5358045
	speed: 0.1308s/iter; left time: 4273.0364s
Epoch: 6 cost time: 5.877671957015991
Epoch: 6, Steps: 168 | Train Loss: 0.6332450 Vali Loss: 0.6615458 Test Loss: 1.4022410
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 7 | loss: 0.6372854
	speed: 0.1296s/iter; left time: 4210.0316s
Epoch: 7 cost time: 5.8215320110321045
Epoch: 7, Steps: 168 | Train Loss: 0.6336349 Vali Loss: 0.6616874 Test Loss: 1.4041638
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 8 | loss: 0.6746786
	speed: 0.1295s/iter; left time: 4187.0730s
Epoch: 8 cost time: 5.844393253326416
Epoch: 8, Steps: 168 | Train Loss: 0.6330475 Vali Loss: 0.6619253 Test Loss: 1.4032007
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 9 | loss: 0.5811106
	speed: 0.1283s/iter; left time: 4127.2353s
Epoch: 9 cost time: 5.83132266998291
Epoch: 9, Steps: 168 | Train Loss: 0.6329710 Vali Loss: 0.6607889 Test Loss: 1.4029300
Validation loss decreased (0.661251 --> 0.660789).  Saving model ...
	iters: 100, epoch: 10 | loss: 0.6420598
	speed: 0.1301s/iter; left time: 4160.8236s
Epoch: 10 cost time: 5.823965549468994
Epoch: 10, Steps: 168 | Train Loss: 0.6332278 Vali Loss: 0.6586653 Test Loss: 1.4030572
Validation loss decreased (0.660789 --> 0.658665).  Saving model ...
	iters: 100, epoch: 11 | loss: 0.5520203
	speed: 0.1308s/iter; left time: 4161.1674s
Epoch: 11 cost time: 5.8885393142700195
Epoch: 11, Steps: 168 | Train Loss: 0.6330407 Vali Loss: 0.6618400 Test Loss: 1.4029061
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 12 | loss: 0.5992062
	speed: 0.1295s/iter; left time: 4099.1236s
Epoch: 12 cost time: 5.893028974533081
Epoch: 12, Steps: 168 | Train Loss: 0.6336396 Vali Loss: 0.6623424 Test Loss: 1.4040693
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 13 | loss: 0.6690363
	speed: 0.1292s/iter; left time: 4069.0370s
Epoch: 13 cost time: 5.794043779373169
Epoch: 13, Steps: 168 | Train Loss: 0.6332582 Vali Loss: 0.6617586 Test Loss: 1.4050498
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 14 | loss: 0.5936581
	speed: 0.1307s/iter; left time: 4092.9380s
Epoch: 14 cost time: 5.924067258834839
Epoch: 14, Steps: 168 | Train Loss: 0.6329179 Vali Loss: 0.6612514 Test Loss: 1.4026198
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 15 | loss: 0.5965531
	speed: 0.1297s/iter; left time: 4039.1118s
Epoch: 15 cost time: 5.831787347793579
Epoch: 15, Steps: 168 | Train Loss: 0.6331318 Vali Loss: 0.6609104 Test Loss: 1.4028003
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1432
test shape: (1432, 1, 192, 867) (1432, 1, 192, 867)
test shape: (1432, 192, 867) (1432, 192, 867)
mse:1.4030569791793823, mae:0.6106378436088562
>>>>>>>Overall time: 208 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=867, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems12_d.csv', dec_in=867, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=867, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems12_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5393
val 621
test 1432
	iters: 100, epoch: 1 | loss: 0.6177838
	speed: 0.0366s/iter; left time: 1227.7965s
Epoch: 1 cost time: 5.865532875061035
Epoch: 1, Steps: 168 | Train Loss: 0.6797039 Vali Loss: 0.6694846 Test Loss: 1.4122880
Validation loss decreased (inf --> 0.669485).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.6438959
	speed: 0.1259s/iter; left time: 4196.9281s
Epoch: 2 cost time: 5.704357147216797
Epoch: 2, Steps: 168 | Train Loss: 0.6362966 Vali Loss: 0.6615345 Test Loss: 1.4066099
Validation loss decreased (0.669485 --> 0.661534).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.5689481
	speed: 0.1258s/iter; left time: 4171.6419s
Epoch: 3 cost time: 5.7258312702178955
Epoch: 3, Steps: 168 | Train Loss: 0.6330533 Vali Loss: 0.6614845 Test Loss: 1.4043895
Validation loss decreased (0.661534 --> 0.661484).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.6553214
	speed: 0.1257s/iter; left time: 4148.2824s
Epoch: 4 cost time: 5.6009886264801025
Epoch: 4, Steps: 168 | Train Loss: 0.6335807 Vali Loss: 0.6612512 Test Loss: 1.4041456
Validation loss decreased (0.661484 --> 0.661251).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.6412400
	speed: 0.1262s/iter; left time: 4143.4117s
Epoch: 5 cost time: 5.760904788970947
Epoch: 5, Steps: 168 | Train Loss: 0.6329767 Vali Loss: 0.6631392 Test Loss: 1.4044172
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 6 | loss: 0.5358045
	speed: 0.1258s/iter; left time: 4108.4688s
Epoch: 6 cost time: 5.648529767990112
Epoch: 6, Steps: 168 | Train Loss: 0.6332450 Vali Loss: 0.6615458 Test Loss: 1.4022410
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 7 | loss: 0.6372854
	speed: 0.1254s/iter; left time: 4075.5493s
Epoch: 7 cost time: 5.713145732879639
Epoch: 7, Steps: 168 | Train Loss: 0.6336349 Vali Loss: 0.6616874 Test Loss: 1.4041638
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 8 | loss: 0.6746786
	speed: 0.1260s/iter; left time: 4072.6597s
Epoch: 8 cost time: 5.699667453765869
Epoch: 8, Steps: 168 | Train Loss: 0.6330475 Vali Loss: 0.6619253 Test Loss: 1.4032007
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 9 | loss: 0.5811106
	speed: 0.1241s/iter; left time: 3992.0322s
Epoch: 9 cost time: 5.6283323764801025
Epoch: 9, Steps: 168 | Train Loss: 0.6329710 Vali Loss: 0.6607889 Test Loss: 1.4029300
Validation loss decreased (0.661251 --> 0.660789).  Saving model ...
	iters: 100, epoch: 10 | loss: 0.6420598
	speed: 0.1242s/iter; left time: 3974.1997s
Epoch: 10 cost time: 5.630125522613525
Epoch: 10, Steps: 168 | Train Loss: 0.6332278 Vali Loss: 0.6586653 Test Loss: 1.4030572
Validation loss decreased (0.660789 --> 0.658665).  Saving model ...
	iters: 100, epoch: 11 | loss: 0.5520203
	speed: 0.1255s/iter; left time: 3992.5723s
Epoch: 11 cost time: 5.691753387451172
Epoch: 11, Steps: 168 | Train Loss: 0.6330407 Vali Loss: 0.6618400 Test Loss: 1.4029061
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 12 | loss: 0.5992062
	speed: 0.1271s/iter; left time: 4022.9105s
Epoch: 12 cost time: 5.740432024002075
Epoch: 12, Steps: 168 | Train Loss: 0.6336396 Vali Loss: 0.6623424 Test Loss: 1.4040693
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 13 | loss: 0.6690363
	speed: 0.1261s/iter; left time: 3970.8424s
Epoch: 13 cost time: 5.662775993347168
Epoch: 13, Steps: 168 | Train Loss: 0.6332582 Vali Loss: 0.6617586 Test Loss: 1.4050498
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 14 | loss: 0.5936581
	speed: 0.1258s/iter; left time: 3939.9415s
Epoch: 14 cost time: 5.693383455276489
Epoch: 14, Steps: 168 | Train Loss: 0.6329179 Vali Loss: 0.6612514 Test Loss: 1.4026198
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 15 | loss: 0.5965531
	speed: 0.1257s/iter; left time: 3916.9429s
Epoch: 15 cost time: 5.660531520843506
Epoch: 15, Steps: 168 | Train Loss: 0.6331318 Vali Loss: 0.6609104 Test Loss: 1.4028003
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems12_d_96_192_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1432
test shape: (1432, 1, 192, 867) (1432, 1, 192, 867)
test shape: (1432, 192, 867) (1432, 192, 867)
mse:1.4030569791793823, mae:0.6106378436088562
>>>>>>>Overall time: 202 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
