Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=212, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=212, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems08_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_336_DLinear_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5463
val 508
test 1349
	iters: 100, epoch: 1 | loss: 0.6844295
	speed: 0.0210s/iter; left time: 710.2610s
Epoch: 1 cost time: 3.0970091819763184
Epoch: 1, Steps: 170 | Train Loss: 0.7316045 Vali Loss: 0.4889547 Test Loss: 1.0257840
Validation loss decreased (inf --> 0.488955).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.7369723
	speed: 0.0688s/iter; left time: 2320.5124s
Epoch: 2 cost time: 2.858691453933716
Epoch: 2, Steps: 170 | Train Loss: 0.7086753 Vali Loss: 0.4857682 Test Loss: 1.0239278
Validation loss decreased (0.488955 --> 0.485768).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.7284695
	speed: 0.0691s/iter; left time: 2318.9877s
Epoch: 3 cost time: 2.8197734355926514
Epoch: 3, Steps: 170 | Train Loss: 0.7079610 Vali Loss: 0.4846309 Test Loss: 1.0242175
Validation loss decreased (0.485768 --> 0.484631).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.7401807
	speed: 0.0690s/iter; left time: 2304.2564s
Epoch: 4 cost time: 2.814692735671997
Epoch: 4, Steps: 170 | Train Loss: 0.7079848 Vali Loss: 0.4845532 Test Loss: 1.0235531
Validation loss decreased (0.484631 --> 0.484553).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.7038367
	speed: 0.0683s/iter; left time: 2269.4755s
Epoch: 5 cost time: 2.8393936157226562
Epoch: 5, Steps: 170 | Train Loss: 0.7075010 Vali Loss: 0.4858776 Test Loss: 1.0267906
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 6 | loss: 0.6613909
	speed: 0.0692s/iter; left time: 2285.7619s
Epoch: 6 cost time: 2.9476444721221924
Epoch: 6, Steps: 170 | Train Loss: 0.7077916 Vali Loss: 0.4866963 Test Loss: 1.0255873
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 7 | loss: 0.7951257
	speed: 0.0699s/iter; left time: 2298.8447s
Epoch: 7 cost time: 2.824896812438965
Epoch: 7, Steps: 170 | Train Loss: 0.7078663 Vali Loss: 0.4847478 Test Loss: 1.0245165
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 8 | loss: 0.6648710
	speed: 0.0695s/iter; left time: 2273.3769s
Epoch: 8 cost time: 2.844646453857422
Epoch: 8, Steps: 170 | Train Loss: 0.7078987 Vali Loss: 0.4840488 Test Loss: 1.0225111
Validation loss decreased (0.484553 --> 0.484049).  Saving model ...
	iters: 100, epoch: 9 | loss: 0.6264324
	speed: 0.0690s/iter; left time: 2245.2007s
Epoch: 9 cost time: 2.801284074783325
Epoch: 9, Steps: 170 | Train Loss: 0.7076265 Vali Loss: 0.4851998 Test Loss: 1.0252205
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 10 | loss: 0.6443157
	speed: 0.0718s/iter; left time: 2323.7650s
Epoch: 10 cost time: 2.9787631034851074
Epoch: 10, Steps: 170 | Train Loss: 0.7075613 Vali Loss: 0.4847721 Test Loss: 1.0237117
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 11 | loss: 0.6881237
	speed: 0.0693s/iter; left time: 2232.1744s
Epoch: 11 cost time: 2.823589324951172
Epoch: 11, Steps: 170 | Train Loss: 0.7075048 Vali Loss: 0.4859550 Test Loss: 1.0251242
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 12 | loss: 0.7682354
	speed: 0.0685s/iter; left time: 2194.0366s
Epoch: 12 cost time: 2.8351352214813232
Epoch: 12, Steps: 170 | Train Loss: 0.7080589 Vali Loss: 0.4851728 Test Loss: 1.0260148
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 13 | loss: 0.6603590
	speed: 0.0685s/iter; left time: 2181.3899s
Epoch: 13 cost time: 2.8170342445373535
Epoch: 13, Steps: 170 | Train Loss: 0.7077110 Vali Loss: 0.4853800 Test Loss: 1.0240250
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems08_d_96_336_DLinear_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1349
test shape: (1349, 1, 336, 212) (1349, 1, 336, 212)
test shape: (1349, 336, 212) (1349, 336, 212)
mse:1.022510051727295, mae:0.6017485857009888
>>>>>>>Overall time: 109 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=212, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='pems08_d.csv', dec_in=212, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=212, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='DLinear', model_id='pems08_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems08_d_96_336_DLinear_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5463
val 508
test 1349
	iters: 100, epoch: 1 | loss: 0.6844295
	speed: 0.0208s/iter; left time: 706.2041s
Epoch: 1 cost time: 3.1228840351104736
Epoch: 1, Steps: 170 | Train Loss: 0.7316045 Vali Loss: 0.4889547 Test Loss: 1.0257840
Validation loss decreased (inf --> 0.488955).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.7369723
	speed: 0.0691s/iter; left time: 2332.1253s
Epoch: 2 cost time: 2.8129942417144775
Epoch: 2, Steps: 170 | Train Loss: 0.7086753 Vali Loss: 0.4857682 Test Loss: 1.0239278
Validation loss decreased (0.488955 --> 0.485768).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.7284695
	speed: 0.0687s/iter; left time: 2305.2663s
Epoch: 3 cost time: 2.8483781814575195
Epoch: 3, Steps: 170 | Train Loss: 0.7079610 Vali Loss: 0.4846309 Test Loss: 1.0242175
Validation loss decreased (0.485768 --> 0.484631).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.7401807
	speed: 0.0698s/iter; left time: 2331.8347s
Epoch: 4 cost time: 2.832152843475342
Epoch: 4, Steps: 170 | Train Loss: 0.7079848 Vali Loss: 0.4845532 Test Loss: 1.0235531
Validation loss decreased (0.484631 --> 0.484553).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.7038367
	speed: 0.0688s/iter; left time: 2285.6185s
Epoch: 5 cost time: 2.886962890625
Epoch: 5, Steps: 170 | Train Loss: 0.7075010 Vali Loss: 0.4858776 Test Loss: 1.0267906
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 6 | loss: 0.6613909
	speed: 0.0690s/iter; left time: 2279.2882s
Epoch: 6 cost time: 2.8013620376586914
Epoch: 6, Steps: 170 | Train Loss: 0.7077916 Vali Loss: 0.4866963 Test Loss: 1.0255873
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 7 | loss: 0.7951257
	speed: 0.0716s/iter; left time: 2353.8754s
Epoch: 7 cost time: 2.8302271366119385
Epoch: 7, Steps: 170 | Train Loss: 0.7078663 Vali Loss: 0.4847478 Test Loss: 1.0245165
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 8 | loss: 0.6648710
	speed: 0.0685s/iter; left time: 2241.9852s
Epoch: 8 cost time: 2.817443609237671
Epoch: 8, Steps: 170 | Train Loss: 0.7078987 Vali Loss: 0.4840488 Test Loss: 1.0225111
Validation loss decreased (0.484553 --> 0.484049).  Saving model ...
	iters: 100, epoch: 9 | loss: 0.6264324
	speed: 0.0685s/iter; left time: 2228.4936s
Epoch: 9 cost time: 2.8164896965026855
Epoch: 9, Steps: 170 | Train Loss: 0.7076265 Vali Loss: 0.4851998 Test Loss: 1.0252205
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 10 | loss: 0.6443157
	speed: 0.0691s/iter; left time: 2236.0266s
Epoch: 10 cost time: 2.8457436561584473
Epoch: 10, Steps: 170 | Train Loss: 0.7075613 Vali Loss: 0.4847721 Test Loss: 1.0237117
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 11 | loss: 0.6881237
	speed: 0.0692s/iter; left time: 2229.8470s
Epoch: 11 cost time: 2.81002140045166
Epoch: 11, Steps: 170 | Train Loss: 0.7075048 Vali Loss: 0.4859550 Test Loss: 1.0251242
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 12 | loss: 0.7682354
	speed: 0.0689s/iter; left time: 2207.1705s
Epoch: 12 cost time: 2.8295676708221436
Epoch: 12, Steps: 170 | Train Loss: 0.7080589 Vali Loss: 0.4851728 Test Loss: 1.0260148
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 13 | loss: 0.6603590
	speed: 0.0681s/iter; left time: 2170.0531s
Epoch: 13 cost time: 2.8451685905456543
Epoch: 13, Steps: 170 | Train Loss: 0.7077110 Vali Loss: 0.4853800 Test Loss: 1.0240250
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems08_d_96_336_DLinear_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1349
test shape: (1349, 1, 336, 212) (1349, 1, 336, 212)
test shape: (1349, 336, 212) (1349, 336, 212)
mse:1.022510051727295, mae:0.6017485857009888
>>>>>>>Overall time: 107 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
