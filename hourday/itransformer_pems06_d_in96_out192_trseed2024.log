Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=130, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems06_d.csv', dec_in=130, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=130, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems06_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems06_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3367
val 332
test 853
	iters: 100, epoch: 1 | loss: 0.4752313
	speed: 0.0363s/iter; left time: 72.7047s
	iters: 200, epoch: 1 | loss: 0.5794482
	speed: 0.0302s/iter; left time: 57.4217s
Epoch: 1 cost time: 7.059001922607422
Epoch: 1, Steps: 210 | Train Loss: 0.7892949 Vali Loss: 0.6721814 Test Loss: 0.5671023
Validation loss decreased (inf --> 0.672181).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 1.0445397
	speed: 0.0867s/iter; left time: 155.2973s
	iters: 200, epoch: 2 | loss: 0.6730481
	speed: 0.0301s/iter; left time: 50.8322s
Epoch: 2 cost time: 6.7720582485198975
Epoch: 2, Steps: 210 | Train Loss: 0.7836902 Vali Loss: 0.7181146 Test Loss: 0.5874538
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6867533
	speed: 0.0899s/iter; left time: 142.1748s
	iters: 200, epoch: 3 | loss: 0.9819114
	speed: 0.0335s/iter; left time: 49.5821s
Epoch: 3 cost time: 7.542173147201538
Epoch: 3, Steps: 210 | Train Loss: 0.7548377 Vali Loss: 0.6574304 Test Loss: 0.5406295
Validation loss decreased (0.672181 --> 0.657430).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.8299447
	speed: 0.0918s/iter; left time: 125.9209s
	iters: 200, epoch: 4 | loss: 0.5727076
	speed: 0.0332s/iter; left time: 42.2317s
Epoch: 4 cost time: 7.423898220062256
Epoch: 4, Steps: 210 | Train Loss: 0.7174855 Vali Loss: 0.6564504 Test Loss: 0.5434356
Validation loss decreased (0.657430 --> 0.656450).  Saving model ...
Updating learning rate to 0.000125
