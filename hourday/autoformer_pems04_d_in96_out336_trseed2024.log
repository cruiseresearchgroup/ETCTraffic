Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.6751434
	speed: 0.2044s/iter; left time: 6519.9594s
Epoch: 1 cost time: 32.69694256782532
Epoch: 1, Steps: 160 | Train Loss: 0.7321318 Vali Loss: 0.5102559 Test Loss: 0.7218946
Validation loss decreased (inf --> 0.510256).  Saving model ...
Traceback (most recent call last):
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 372, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 493, in _save
    zip_file.write_record(name, buf_value, len(buf_value))
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 373, in save
    return
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 3441024 vs 3440912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 214, in train
    early_stopping(vali_loss, self.model, path)
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 43, in __call__
    self.save_checkpoint(val_loss, model, path)
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 57, in save_checkpoint
    torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 374, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
OSError: [Errno 122] Disk quota exceeded
terminate called after throwing an instance of 'c10::Error'
  what():  [enforce fail at inline_container.cc:274] . unexpected pos 3441024 vs 3440912
frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x14ded4d426a7 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1c99500 (0x14df140a9500 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x1c956d3 (0x14df140a56d3 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x14df140aa609 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x14df140ab141 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x14df140ab935 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #6: <unknown function> + 0x654323 (0x14df2377c323 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x2c2b90 (0x14df233eab90 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x2c3cfe (0x14df233ebcfe in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: python() [0x4e0800]
frame #10: python() [0x4f16a8]
frame #11: python() [0x4f1691]
frame #12: python() [0x4f1691]
frame #13: python() [0x4f1691]
frame #14: python() [0x4f1691]
frame #15: python() [0x4c9280]
<omitting python frames>
frame #21: __libc_start_main + 0xe5 (0x14df3253bd85 in /lib64/libc.so.6)
frame #22: python() [0x57a64d]

Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.6725689
	speed: 0.2314s/iter; left time: 7383.1995s
Epoch: 1 cost time: 36.85058307647705
Epoch: 1, Steps: 160 | Train Loss: 0.7339589 Vali Loss: 0.5275082 Test Loss: 0.7410138
Validation loss decreased (inf --> 0.527508).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.6299830
	speed: 0.5800s/iter; left time: 18410.3181s
Epoch: 2 cost time: 36.417272090911865
Epoch: 2, Steps: 160 | Train Loss: 0.6648221 Vali Loss: 0.5182230 Test Loss: 0.7319148
Validation loss decreased (0.527508 --> 0.518223).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.6873887
	speed: 0.5796s/iter; left time: 18303.5956s
Epoch: 3 cost time: 36.482192039489746
Epoch: 3, Steps: 160 | Train Loss: 0.6612222 Vali Loss: 0.5178753 Test Loss: 0.8493087
Validation loss decreased (0.518223 --> 0.517875).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.6230840
	speed: 0.5767s/iter; left time: 18121.0933s
Epoch: 4 cost time: 36.13232707977295
Epoch: 4, Steps: 160 | Train Loss: 0.6589826 Vali Loss: 0.4989799 Test Loss: 0.7130022
Validation loss decreased (0.517875 --> 0.498980).  Saving model ...
	iters: 100, epoch: 5 | loss: 0.6926376
	speed: 0.5777s/iter; left time: 18060.1857s
Epoch: 5 cost time: 36.51681041717529
Epoch: 5, Steps: 160 | Train Loss: 0.6585364 Vali Loss: 0.5020863 Test Loss: 0.7195868
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 6 | loss: 0.5493033
	speed: 0.5757s/iter; left time: 17903.5625s
Epoch: 6 cost time: 36.1947078704834
Epoch: 6, Steps: 160 | Train Loss: 0.6416958 Vali Loss: 0.5036284 Test Loss: 0.7199230
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 7 | loss: 0.5869563
	speed: 0.5782s/iter; left time: 17888.8721s
Epoch: 7 cost time: 36.53517413139343
Epoch: 7, Steps: 160 | Train Loss: 0.6251622 Vali Loss: 0.5004539 Test Loss: 0.7191200
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 8 | loss: 0.6776732
	speed: 0.5788s/iter; left time: 17814.9569s
Epoch: 8 cost time: 36.508760929107666
Epoch: 8, Steps: 160 | Train Loss: 0.6050926 Vali Loss: 0.4989637 Test Loss: 0.7282047
Validation loss decreased (0.498980 --> 0.498964).  Saving model ...
	iters: 100, epoch: 9 | loss: 0.5211530
	speed: 0.5785s/iter; left time: 17714.0322s
Epoch: 9 cost time: 36.28603386878967
Epoch: 9, Steps: 160 | Train Loss: 0.5711881 Vali Loss: 0.5038492 Test Loss: 0.7540774
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 10 | loss: 0.5558803
	speed: 0.5747s/iter; left time: 17505.7413s
Epoch: 10 cost time: 36.228809118270874
Epoch: 10, Steps: 160 | Train Loss: 0.5424355 Vali Loss: 0.5031066 Test Loss: 0.7435197
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 11 | loss: 0.4848230
	speed: 0.5806s/iter; left time: 17591.8601s
Epoch: 11 cost time: 36.81350016593933
Epoch: 11, Steps: 160 | Train Loss: 0.5150527 Vali Loss: 0.5078313 Test Loss: 0.7599434
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 12 | loss: 0.6899640
	speed: 0.5835s/iter; left time: 17587.0142s
Epoch: 12 cost time: 37.113163232803345
Epoch: 12, Steps: 160 | Train Loss: 0.5321795 Vali Loss: 0.5050761 Test Loss: 0.7339165
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 13 | loss: 0.5208195
	speed: 0.5794s/iter; left time: 17370.7401s
Epoch: 13 cost time: 36.50173044204712
Epoch: 13, Steps: 160 | Train Loss: 0.5117571 Vali Loss: 0.5105232 Test Loss: 0.7607528
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 822) (1257, 1, 336, 822)
test shape: (1257, 336, 822) (1257, 336, 822)
mse:0.7282061576843262, mae:0.5693559646606445
>>>>>>>Overall time: 780 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
