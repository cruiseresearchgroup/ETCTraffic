Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116408134.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 84, in train
    train_data, train_loader = self._get_data(flag='train')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 74, in data_provider
    data_set = Data(
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 320, in __init__
    self.__read_data__()
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_loader.py", line 324, in __read_data__
    df_raw = pd.read_csv(os.path.join(self.root_path,
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/jobfs/116443177.gadi-pbs/timesnet/lib/python3.8/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../../data/pems/pems04_d.csv'
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.5695893
	speed: 0.1520s/iter; left time: 5002.3741s
Epoch: 1 cost time: 24.91617178916931
Epoch: 1, Steps: 165 | Train Loss: 0.6441565 Vali Loss: 0.4467120 Test Loss: 0.7024924
Validation loss decreased (inf --> 0.446712).  Saving model ...
Traceback (most recent call last):
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 372, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 493, in _save
    zip_file.write_record(name, buf_value, len(buf_value))
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 373, in save
    return
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 15524544 vs 15524432

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 214, in train
    early_stopping(vali_loss, self.model, path)
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 43, in __call__
    self.save_checkpoint(val_loss, model, path)
  File "/g/data/hn98/du/exlts/hourdayweek/utils/tools.py", line 57, in save_checkpoint
    torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 374, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
OSError: [Errno 122] Disk quota exceeded
terminate called after throwing an instance of 'c10::Error'
  what():  [enforce fail at inline_container.cc:274] . unexpected pos 15524544 vs 15524432
frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x14bcf87b56a7 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1c99500 (0x14bd37b1c500 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x1c956d3 (0x14bd37b186d3 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x14bd37b1d609 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x14bd37b1e141 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x14bd37b1e935 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #6: <unknown function> + 0x654323 (0x14bd471ef323 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x2c2b90 (0x14bd46e5db90 in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x2c3cfe (0x14bd46e5ecfe in /jobfs/116444160.gadi-pbs/timesnet/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: python() [0x4e0800]
frame #10: python() [0x4f16a8]
frame #11: python() [0x4f1691]
frame #12: python() [0x4f1691]
frame #13: python() [0x4f1691]
frame #14: python() [0x4f1691]
frame #15: python() [0x4c9280]
<omitting python frames>
frame #21: __libc_start_main + 0xe5 (0x14bd55faed85 in /lib64/libc.so.6)
frame #22: python() [0x57a64d]

Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=822, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems04_d.csv', dec_in=822, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=822, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems04_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5287
val 607
test 1401
	iters: 100, epoch: 1 | loss: 0.5695893
	speed: 0.1694s/iter; left time: 5573.1899s
Epoch: 1 cost time: 26.99486017227173
Epoch: 1, Steps: 165 | Train Loss: 0.6441566 Vali Loss: 0.4467151 Test Loss: 0.7024859
Validation loss decreased (inf --> 0.446715).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.5585571
	speed: 0.4665s/iter; left time: 15270.7015s
Epoch: 2 cost time: 25.911360025405884
Epoch: 2, Steps: 165 | Train Loss: 0.5766777 Vali Loss: 0.4307448 Test Loss: 0.7491057
Validation loss decreased (0.446715 --> 0.430745).  Saving model ...
	iters: 100, epoch: 3 | loss: 0.5393766
	speed: 0.4668s/iter; left time: 15203.6720s
Epoch: 3 cost time: 25.90854263305664
Epoch: 3, Steps: 165 | Train Loss: 0.5419594 Vali Loss: 0.4327148 Test Loss: 0.7811644
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 4 | loss: 0.4983212
	speed: 0.4682s/iter; left time: 15172.8246s
Epoch: 4 cost time: 26.00760054588318
Epoch: 4, Steps: 165 | Train Loss: 0.5114652 Vali Loss: 0.4354700 Test Loss: 0.8256577
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 5 | loss: 0.4368918
	speed: 0.4651s/iter; left time: 14995.7086s
Epoch: 5 cost time: 25.8389995098114
Epoch: 5, Steps: 165 | Train Loss: 0.4663890 Vali Loss: 0.4348801 Test Loss: 0.7664231
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 6 | loss: 0.4106817
	speed: 0.4724s/iter; left time: 15152.4399s
Epoch: 6 cost time: 26.49015712738037
Epoch: 6, Steps: 165 | Train Loss: 0.4280010 Vali Loss: 0.4431293 Test Loss: 0.7847478
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 7 | loss: 0.3904111
	speed: 0.4636s/iter; left time: 14795.0443s
Epoch: 7 cost time: 25.813013792037964
Epoch: 7, Steps: 165 | Train Loss: 0.3931228 Vali Loss: 0.4445111 Test Loss: 0.8126581
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems04_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl192_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1401
test shape: (1401, 1, 192, 822) (1401, 1, 192, 822)
test shape: (1401, 192, 822) (1401, 192, 822)
mse:0.7491105198860168, mae:0.5802500247955322
>>>>>>>Overall time: 355 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
