Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=151, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems03_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.8433452
	speed: 0.1712s/iter; left time: 5460.9810s
Epoch: 1 cost time: 27.44384455680847
Epoch: 1, Steps: 160 | Train Loss: 0.8167845 Vali Loss: 0.6916485 Test Loss: 1.0576400
Validation loss decreased (inf --> 0.691649).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.8004382
	speed: 0.4395s/iter; left time: 13949.5727s
Epoch: 2 cost time: 28.02077031135559
Epoch: 2, Steps: 160 | Train Loss: 0.7638310 Vali Loss: 0.7142472 Test Loss: 1.0638294
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 3 | loss: 0.8164257
	speed: 0.4364s/iter; left time: 13782.9641s
Epoch: 3 cost time: 27.046956777572632
Epoch: 3, Steps: 160 | Train Loss: 0.6981651 Vali Loss: 0.7381921 Test Loss: 1.0933295
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 4 | loss: 0.5485784
	speed: 0.4329s/iter; left time: 13602.9485s
Epoch: 4 cost time: 30.78637433052063
Epoch: 4, Steps: 160 | Train Loss: 0.5627844 Vali Loss: 0.7546817 Test Loss: 1.1063311
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 5 | loss: 0.4302259
	speed: 0.4858s/iter; left time: 15186.5507s
Epoch: 5 cost time: 28.65589666366577
Epoch: 5, Steps: 160 | Train Loss: 0.4719027 Vali Loss: 0.7845351 Test Loss: 1.1243654
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 6 | loss: 0.4323106
	speed: 0.4897s/iter; left time: 15228.9548s
Epoch: 6 cost time: 36.733197927474976
Epoch: 6, Steps: 160 | Train Loss: 0.4935463 Vali Loss: 0.7792608 Test Loss: 1.1392511
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems03_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 151) (1257, 1, 336, 151)
test shape: (1257, 336, 151) (1257, 336, 151)
mse:1.0576395988464355, mae:0.6302143931388855
>>>>>>>Overall time: 305 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=151, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems03_d.csv', dec_in=151, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=151, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems03_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems03_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5143
val 463
test 1257
	iters: 100, epoch: 1 | loss: 0.8433452
	speed: 0.1755s/iter; left time: 5599.0228s
Epoch: 1 cost time: 27.95185351371765
Epoch: 1, Steps: 160 | Train Loss: 0.8167845 Vali Loss: 0.6916485 Test Loss: 1.0576400
Validation loss decreased (inf --> 0.691649).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.8004382
	speed: 0.4443s/iter; left time: 14101.5030s
Epoch: 2 cost time: 27.94193434715271
Epoch: 2, Steps: 160 | Train Loss: 0.7638310 Vali Loss: 0.7142433 Test Loss: 1.0638291
EarlyStopping counter: 1 out of 5
	iters: 100, epoch: 3 | loss: 0.8164289
	speed: 0.4408s/iter; left time: 13922.2593s
Epoch: 3 cost time: 27.680785179138184
Epoch: 3, Steps: 160 | Train Loss: 0.6984381 Vali Loss: 0.7306093 Test Loss: 1.0987736
EarlyStopping counter: 2 out of 5
	iters: 100, epoch: 4 | loss: 0.5432519
	speed: 0.4416s/iter; left time: 13876.3314s
Epoch: 4 cost time: 27.726562023162842
Epoch: 4, Steps: 160 | Train Loss: 0.5643802 Vali Loss: 0.7631912 Test Loss: 1.1109086
EarlyStopping counter: 3 out of 5
	iters: 100, epoch: 5 | loss: 0.5252557
	speed: 0.4425s/iter; left time: 13833.5033s
Epoch: 5 cost time: 27.825500011444092
Epoch: 5, Steps: 160 | Train Loss: 0.5108242 Vali Loss: 0.7900180 Test Loss: 1.1042106
EarlyStopping counter: 4 out of 5
	iters: 100, epoch: 6 | loss: 0.4513510
	speed: 0.4433s/iter; left time: 13787.2730s
Epoch: 6 cost time: 27.85793709754944
Epoch: 6, Steps: 160 | Train Loss: 0.4534802 Vali Loss: 0.7963213 Test Loss: 1.1094457
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems03_d_96_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1257
test shape: (1257, 1, 336, 151) (1257, 1, 336, 151)
test shape: (1257, 336, 151) (1257, 336, 151)
mse:1.057639718055725, mae:0.6302143931388855
>>>>>>>Overall time: 297 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
