Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=103, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=128, data='custom', data_path='pems05_d.csv', dec_in=103, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=103, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='MSE', lradj='type3', mask_rate=0.25, model='Autoformer', model_id='pems05_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=5, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=200, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems05_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2886
val 346
test 784
Epoch: 1 cost time: 10.101653575897217
Epoch: 1, Steps: 90 | Train Loss: 0.7217434 Vali Loss: 0.8068126 Test Loss: 0.6198875
Validation loss decreased (inf --> 0.806813).  Saving model ...
Epoch: 2 cost time: 9.211684226989746
Epoch: 2, Steps: 90 | Train Loss: 0.5211418 Vali Loss: 0.6442323 Test Loss: 0.5861365
Validation loss decreased (0.806813 --> 0.644232).  Saving model ...
Epoch: 3 cost time: 9.549155950546265
Epoch: 3, Steps: 90 | Train Loss: 0.4463199 Vali Loss: 0.7526147 Test Loss: 0.6438167
EarlyStopping counter: 1 out of 5
Epoch: 4 cost time: 9.148674011230469
Epoch: 4, Steps: 90 | Train Loss: 0.3828406 Vali Loss: 0.6405574 Test Loss: 0.6517078
Validation loss decreased (0.644232 --> 0.640557).  Saving model ...
Epoch: 5 cost time: 9.175138473510742
Epoch: 5, Steps: 90 | Train Loss: 0.3323477 Vali Loss: 0.6429120 Test Loss: 0.6197981
EarlyStopping counter: 1 out of 5
Epoch: 6 cost time: 9.19800877571106
Epoch: 6, Steps: 90 | Train Loss: 0.2842408 Vali Loss: 0.6520215 Test Loss: 0.6730314
EarlyStopping counter: 2 out of 5
Epoch: 7 cost time: 9.71887469291687
Epoch: 7, Steps: 90 | Train Loss: 0.2451925 Vali Loss: 0.6055484 Test Loss: 0.6575074
Validation loss decreased (0.640557 --> 0.605548).  Saving model ...
Epoch: 8 cost time: 9.365619897842407
Epoch: 8, Steps: 90 | Train Loss: 0.2152518 Vali Loss: 0.5947553 Test Loss: 0.6496989
Validation loss decreased (0.605548 --> 0.594755).  Saving model ...
Epoch: 9 cost time: 9.257280349731445
Epoch: 9, Steps: 90 | Train Loss: 0.1937384 Vali Loss: 0.5994065 Test Loss: 0.6510254
EarlyStopping counter: 1 out of 5
Epoch: 10 cost time: 9.336461544036865
Epoch: 10, Steps: 90 | Train Loss: 0.1778006 Vali Loss: 0.6049656 Test Loss: 0.6376762
EarlyStopping counter: 2 out of 5
Epoch: 11 cost time: 9.204182386398315
Epoch: 11, Steps: 90 | Train Loss: 0.1655216 Vali Loss: 0.6153124 Test Loss: 0.6661029
EarlyStopping counter: 3 out of 5
Epoch: 12 cost time: 9.166867733001709
Epoch: 12, Steps: 90 | Train Loss: 0.1564712 Vali Loss: 0.6367104 Test Loss: 0.6357992
EarlyStopping counter: 4 out of 5
Epoch: 13 cost time: 9.754734992980957
Epoch: 13, Steps: 90 | Train Loss: 0.1491230 Vali Loss: 0.6081209 Test Loss: 0.6321684
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_pems05_d_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 784
test shape: (784, 1, 96, 103) (784, 1, 96, 103)
test shape: (784, 96, 103) (784, 96, 103)
mse:0.6496990323066711, mae:0.5223674178123474
>>>>>>>Overall time: 270 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
