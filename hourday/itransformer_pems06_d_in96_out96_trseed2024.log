Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=130, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems06_d.csv', dec_in=130, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=130, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems06_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems06_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3463
val 428
test 949
	iters: 100, epoch: 1 | loss: 0.7821745
	speed: 0.0362s/iter; left time: 74.5705s
	iters: 200, epoch: 1 | loss: 0.6327164
	speed: 0.0303s/iter; left time: 59.4802s
Epoch: 1 cost time: 7.24908185005188
Epoch: 1, Steps: 216 | Train Loss: 0.5737096 Vali Loss: 0.5589035 Test Loss: 0.4403350
Validation loss decreased (inf --> 0.558903).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.4610350
	speed: 0.0897s/iter; left time: 165.5703s
	iters: 200, epoch: 2 | loss: 0.6910359
	speed: 0.0291s/iter; left time: 50.7754s
Epoch: 2 cost time: 6.783329963684082
Epoch: 2, Steps: 216 | Train Loss: 0.5549239 Vali Loss: 0.5896208 Test Loss: 0.4594888
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6948715
	speed: 0.0900s/iter; left time: 146.5564s
	iters: 200, epoch: 3 | loss: 0.4698676
	speed: 0.0303s/iter; left time: 46.3101s
Epoch: 3 cost time: 7.0215208530426025
Epoch: 3, Steps: 216 | Train Loss: 0.5319927 Vali Loss: 0.5443923 Test Loss: 0.4291938
Validation loss decreased (0.558903 --> 0.544392).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.4873140
	speed: 0.0881s/iter; left time: 124.4801s
	iters: 200, epoch: 4 | loss: 0.5024862
	speed: 0.0300s/iter; left time: 39.3262s
Epoch: 4 cost time: 6.776823997497559
Epoch: 4, Steps: 216 | Train Loss: 0.4974011 Vali Loss: 0.5270578 Test Loss: 0.4142348
Validation loss decreased (0.544392 --> 0.527058).  Saving model ...
Updating learning rate to 0.000125
