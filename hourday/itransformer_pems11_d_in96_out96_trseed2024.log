Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=521, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems11_d.csv', dec_in=521, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=521, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems11_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=521, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems11_d.csv', dec_in=521, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=521, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems11_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=16, c_out=521, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems11_d.csv', dec_in=521, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=4, embed='timeF', enc_in=521, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='MSE', lradj='type1', mask_rate=0.25, model='iTransformer', model_id='pems11_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems11_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems11_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>start training : long_term_forecast_pems11_d_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5319
train 5079
train 5223
val 453
val 693
val 597
test 1479
test 1239
test 1383
	iters: 100, epoch: 1 | loss: 0.4026068
	speed: 0.0756s/iter; left time: 243.5265s
	iters: 100, epoch: 1 | loss: 0.4158861
	speed: 0.0771s/iter; left time: 243.7317s
	iters: 100, epoch: 1 | loss: 0.5204987
	speed: 0.0802s/iter; left time: 246.1416s
	iters: 200, epoch: 1 | loss: 0.3052599
	speed: 0.0704s/iter; left time: 219.7378s
	iters: 200, epoch: 1 | loss: 0.3598686
	speed: 0.0722s/iter; left time: 221.1513s
	iters: 200, epoch: 1 | loss: 0.4917679
	speed: 0.0751s/iter; left time: 223.2272s
	iters: 300, epoch: 1 | loss: 0.4294465
	speed: 0.0706s/iter; left time: 213.1664s
	iters: 300, epoch: 1 | loss: 0.4772096
	speed: 0.0723s/iter; left time: 214.0577s
	iters: 300, epoch: 1 | loss: 0.4839534
	speed: 0.0749s/iter; left time: 215.0100s
Epoch: 1 cost time: 24.00675106048584
Epoch: 1 cost time: 24.129652738571167
Epoch: 1 cost time: 24.383887767791748
Epoch: 1, Steps: 332 | Train Loss: 0.3882940 Vali Loss: 0.4204149 Test Loss: 22664.9218750
Validation loss decreased (inf --> 0.420415).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 326 | Train Loss: 0.4716339 Vali Loss: 0.4880976 Test Loss: 43992.3242188
Validation loss decreased (inf --> 0.488098).  Saving model ...
Updating learning rate to 0.001
Epoch: 1, Steps: 317 | Train Loss: 0.5385142 Vali Loss: 0.5163644 Test Loss: 75662.6406250
Validation loss decreased (inf --> 0.516364).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3794246
	speed: 0.1914s/iter; left time: 552.8416s
	iters: 100, epoch: 2 | loss: 0.4137838
	speed: 0.1906s/iter; left time: 540.3469s
	iters: 100, epoch: 2 | loss: 0.6147882
	speed: 0.1936s/iter; left time: 533.0785s
	iters: 200, epoch: 2 | loss: 0.3893253
	speed: 0.0703s/iter; left time: 196.1242s
	iters: 200, epoch: 2 | loss: 0.3937788
	speed: 0.0713s/iter; left time: 194.8888s
	iters: 200, epoch: 2 | loss: 0.6689066
	speed: 0.0747s/iter; left time: 198.3070s
	iters: 300, epoch: 2 | loss: 0.4423876
	speed: 0.0704s/iter; left time: 189.2178s
	iters: 300, epoch: 2 | loss: 0.4209880
	speed: 0.0713s/iter; left time: 187.8376s
Epoch: 2 cost time: 23.7262864112854
	iters: 300, epoch: 2 | loss: 0.6449942
	speed: 0.0747s/iter; left time: 190.6884s
Epoch: 2 cost time: 23.719022512435913
Epoch: 2 cost time: 24.053980350494385
Epoch: 2, Steps: 332 | Train Loss: 0.3894187 Vali Loss: 0.5151127 Test Loss: 27304.8925781
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
Epoch: 2, Steps: 326 | Train Loss: 0.4575139 Vali Loss: 0.5031721 Test Loss: 43059.3789062
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
Epoch: 2, Steps: 317 | Train Loss: 0.5619870 Vali Loss: 0.7127585 Test Loss: 81677.1953125
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3873569
	speed: 0.1839s/iter; left time: 470.3349s
	iters: 100, epoch: 3 | loss: 0.3926819
	speed: 0.1833s/iter; left time: 459.8536s
	iters: 100, epoch: 3 | loss: 0.9206222
	speed: 0.1866s/iter; left time: 454.6363s
	iters: 200, epoch: 3 | loss: 0.3295768
	speed: 0.0704s/iter; left time: 172.9255s
	iters: 200, epoch: 3 | loss: 0.4308998
	speed: 0.0710s/iter; left time: 171.0992s
	iters: 200, epoch: 3 | loss: 0.6554433
	speed: 0.0746s/iter; left time: 174.2770s
	iters: 300, epoch: 3 | loss: 0.3244148
	speed: 0.0704s/iter; left time: 165.8635s
	iters: 300, epoch: 3 | loss: 0.3430683
	speed: 0.0717s/iter; left time: 165.4727s
Epoch: 3 cost time: 23.725960731506348
Epoch: 3 cost time: 23.73783230781555
	iters: 300, epoch: 3 | loss: 0.6524229
	speed: 0.0746s/iter; left time: 166.8355s
Epoch: 3 cost time: 24.056527376174927
Epoch: 3, Steps: 332 | Train Loss: 0.3961238 Vali Loss: 0.4423376 Test Loss: 23436.4296875
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00025
Epoch: 3, Steps: 326 | Train Loss: 0.4252605 Vali Loss: 0.4522813 Test Loss: 41925.9062500
Validation loss decreased (0.488098 --> 0.452281).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3, Steps: 317 | Train Loss: 0.7182903 Vali Loss: 0.6905599 Test Loss: 81678.5703125
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3134770
	speed: 0.1849s/iter; left time: 411.4911s
	iters: 100, epoch: 4 | loss: 0.4882988
	speed: 0.1905s/iter; left time: 415.9034s
	iters: 100, epoch: 4 | loss: 0.7508146
	speed: 0.2021s/iter; left time: 428.4417s
	iters: 200, epoch: 4 | loss: 0.4771857
	speed: 0.0705s/iter; left time: 149.8384s
	iters: 200, epoch: 4 | loss: 0.3600968
	speed: 0.0718s/iter; left time: 149.6115s
	iters: 200, epoch: 4 | loss: 0.6238576
	speed: 0.0748s/iter; left time: 151.0557s
	iters: 300, epoch: 4 | loss: 0.3445178
	speed: 0.0707s/iter; left time: 143.2565s
	iters: 300, epoch: 4 | loss: 0.4042042
	speed: 0.0711s/iter; left time: 141.0892s
Epoch: 4 cost time: 23.787110090255737
Epoch: 4 cost time: 23.738936185836792
	iters: 300, epoch: 4 | loss: 0.7028168
	speed: 0.0749s/iter; left time: 143.8480s
Epoch: 4 cost time: 24.098926782608032
Epoch: 4, Steps: 332 | Train Loss: 0.3690352 Vali Loss: 0.4298485 Test Loss: 21712.9511719
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems11_d_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1479
Epoch: 4, Steps: 326 | Train Loss: 0.4023247 Vali Loss: 0.4366919 Test Loss: 40658.0820312
Validation loss decreased (0.452281 --> 0.436692).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4, Steps: 317 | Train Loss: 0.7097801 Vali Loss: 0.6604666 Test Loss: 81908.2500000
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_pems11_d_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el4_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1239
test shape: (1479, 1, 96, 521) (1479, 1, 96, 521)
test shape: (1479, 96, 521) (1479, 96, 521)
mse:22664.7265625, mae:3.4021241664886475
>>>>>>>Overall time: 143 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
	iters: 100, epoch: 5 | loss: 0.4378490
	speed: 0.1956s/iter; left time: 363.1861s
test shape: (1239, 1, 336, 521) (1239, 1, 336, 521)
test shape: (1239, 336, 521) (1239, 336, 521)
	iters: 200, epoch: 5 | loss: 0.3299566
	speed: 0.0720s/iter; left time: 126.4214s
mse:75662.5703125, mae:8.31067180633545
>>>>>>>Overall time: 152 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
